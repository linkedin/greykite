

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>sklearn.model_selection._split &mdash; Greykite Library  documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/sg_gallery-rendered-html.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 

  
  <script src="../../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../../index.html" class="icon icon-home"> Greykite Library
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Greykite Info</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/greykite/overview.html">Overview</a></li>
</ul>
<p class="caption"><span class="caption-text">Quick Start</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../gallery/quickstart/index.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../gallery/tutorials/index.html">Tutorials</a></li>
</ul>
<p class="caption"><span class="caption-text">Step by Step</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/stepbystep/0000_stepbystep.html">Forecasting Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/stepbystep/0100_choose_model.html">Choose a Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/stepbystep/0200_choose_template.html">Choose a Model Template</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/stepbystep/0300_input.html">Examine Input Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/stepbystep/0400_configuration.html">Configure a Forecast</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/stepbystep/0500_output.html">Check Forecast Result</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/stepbystep/0600_debug.html">Debugging</a></li>
</ul>
<p class="caption"><span class="caption-text">Tuning the Model Components</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0100_introduction.html">Greykite models and components</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0200_growth.html">Growth</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0300_seasonality.html">Seasonality</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0400_events.html">Holidays and Events</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0500_changepoints.html">Changepoints</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0600_custom.html">Custom Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0700_regressors.html">Regressors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0800_autoregression.html">Auto-regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/0900_uncertainty.html">Uncertainty Intervals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/model_components/1000_override.html">Pre-processing, Selective Grid Search</a></li>
</ul>
<p class="caption"><span class="caption-text">Benchmarking</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/benchmarking/benchmarking.html">Benchmarking</a></li>
</ul>
<p class="caption"><span class="caption-text">Miscellaneous</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/miscellaneous/reconcile_forecasts.html">Reconcile Forecasts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/miscellaneous/store_model.html">Model store and load</a></li>
</ul>
<p class="caption"><span class="caption-text">Changelog</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/changelog/changelog.html">Changelog</a></li>
</ul>
<p class="caption"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../pages/autodoc/doc.html">Docs</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Greykite Library</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>sklearn.model_selection._split</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for sklearn.model_selection._split</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">The :mod:`sklearn.model_selection._split` module includes classes and</span>
<span class="sd">functions to split the data based on a preset strategy.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Author: Alexandre Gramfort &lt;alexandre.gramfort@inria.fr&gt;,</span>
<span class="c1">#         Gael Varoquaux &lt;gael.varoquaux@normalesup.org&gt;,</span>
<span class="c1">#         Olivier Grisel &lt;olivier.grisel@ensta.org&gt;</span>
<span class="c1">#         Raghav RV &lt;rvraghav93@gmail.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Iterable</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span><span class="p">,</span> <span class="n">combinations</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">ceil</span><span class="p">,</span> <span class="n">floor</span>
<span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABCMeta</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">inspect</span> <span class="kn">import</span> <span class="n">signature</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">comb</span>

<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">indexable</span><span class="p">,</span> <span class="n">check_random_state</span><span class="p">,</span> <span class="n">_safe_indexing</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">_approximate_mode</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">_num_samples</span><span class="p">,</span> <span class="n">column_or_1d</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">check_array</span>
<span class="kn">from</span> <span class="nn">..utils.validation</span> <span class="kn">import</span> <span class="n">_deprecate_positional_args</span>
<span class="kn">from</span> <span class="nn">..utils.multiclass</span> <span class="kn">import</span> <span class="n">type_of_target</span>
<span class="kn">from</span> <span class="nn">..base</span> <span class="kn">import</span> <span class="n">_pprint</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BaseCrossValidator&#39;</span><span class="p">,</span>
           <span class="s1">&#39;KFold&#39;</span><span class="p">,</span>
           <span class="s1">&#39;GroupKFold&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LeaveOneGroupOut&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LeaveOneOut&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LeavePGroupsOut&#39;</span><span class="p">,</span>
           <span class="s1">&#39;LeavePOut&#39;</span><span class="p">,</span>
           <span class="s1">&#39;RepeatedStratifiedKFold&#39;</span><span class="p">,</span>
           <span class="s1">&#39;RepeatedKFold&#39;</span><span class="p">,</span>
           <span class="s1">&#39;ShuffleSplit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;GroupShuffleSplit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;StratifiedKFold&#39;</span><span class="p">,</span>
           <span class="s1">&#39;StratifiedShuffleSplit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;PredefinedSplit&#39;</span><span class="p">,</span>
           <span class="s1">&#39;train_test_split&#39;</span><span class="p">,</span>
           <span class="s1">&#39;check_cv&#39;</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">BaseCrossValidator</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for all cross-validators</span>

<span class="sd">    Implementations must define `_iter_test_masks` or `_iter_test_indices`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_test_masks</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
            <span class="n">train_index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">test_index</span><span class="p">)]</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
            <span class="k">yield</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span>

    <span class="c1"># Since subclasses must implement either _iter_test_masks or</span>
    <span class="c1"># _iter_test_indices, neither can be abstract.</span>
    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generates boolean masks corresponding to test sets.</span>

<span class="sd">        By default, delegates to _iter_test_indices(X, y, groups)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_test_indices</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
            <span class="n">test_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">test_mask</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">yield</span> <span class="n">test_mask</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generates integer indices corresponding to test sets.&quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_build_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LeaveOneOut</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Leave-One-Out cross-validator</span>

<span class="sd">    Provides train/test indices to split data in train/test sets. Each</span>
<span class="sd">    sample is used once as a test set (singleton) while the remaining</span>
<span class="sd">    samples form the training set.</span>

<span class="sd">    Note: ``LeaveOneOut()`` is equivalent to ``KFold(n_splits=n)`` and</span>
<span class="sd">    ``LeavePOut(p=1)`` where ``n`` is the number of samples.</span>

<span class="sd">    Due to the high number of test sets (which is the same as the</span>
<span class="sd">    number of samples) this cross-validation method can be very costly.</span>
<span class="sd">    For large datasets one should favor :class:`KFold`, :class:`ShuffleSplit`</span>
<span class="sd">    or :class:`StratifiedKFold`.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;leave_one_out&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import LeaveOneOut</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2])</span>
<span class="sd">    &gt;&gt;&gt; loo = LeaveOneOut()</span>
<span class="sd">    &gt;&gt;&gt; loo.get_n_splits(X)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(loo)</span>
<span class="sd">    LeaveOneOut()</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in loo.split(X):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...     print(X_train, X_test, y_train, y_test)</span>
<span class="sd">    TRAIN: [1] TEST: [0]</span>
<span class="sd">    [[3 4]] [[1 2]] [2] [1]</span>
<span class="sd">    TRAIN: [0] TEST: [1]</span>
<span class="sd">    [[1 2]] [[3 4]] [1] [2]</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    LeaveOneGroupOut : For splitting the data according to explicit,</span>
<span class="sd">        domain-specific stratification of the dataset.</span>
<span class="sd">    GroupKFold : K-fold iterator variant with non-overlapping groups.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Cannot perform LeaveOneOut with n_samples=</span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">n_samples</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;X&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LeavePOut</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Leave-P-Out cross-validator</span>

<span class="sd">    Provides train/test indices to split data in train/test sets. This results</span>
<span class="sd">    in testing on all distinct samples of size p, while the remaining n - p</span>
<span class="sd">    samples form the training set in each iteration.</span>

<span class="sd">    Note: ``LeavePOut(p)`` is NOT equivalent to</span>
<span class="sd">    ``KFold(n_splits=n_samples // p)`` which creates non-overlapping test sets.</span>

<span class="sd">    Due to the high number of iterations which grows combinatorically with the</span>
<span class="sd">    number of samples this cross-validation method can be very costly. For</span>
<span class="sd">    large datasets one should favor :class:`KFold`, :class:`StratifiedKFold`</span>
<span class="sd">    or :class:`ShuffleSplit`.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;leave_p_out&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    p : int</span>
<span class="sd">        Size of the test sets. Must be strictly less than the number of</span>
<span class="sd">        samples.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import LeavePOut</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; lpo = LeavePOut(2)</span>
<span class="sd">    &gt;&gt;&gt; lpo.get_n_splits(X)</span>
<span class="sd">    6</span>
<span class="sd">    &gt;&gt;&gt; print(lpo)</span>
<span class="sd">    LeavePOut(p=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in lpo.split(X):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    TRAIN: [1 3] TEST: [0 2]</span>
<span class="sd">    TRAIN: [1 2] TEST: [0 3]</span>
<span class="sd">    TRAIN: [0 3] TEST: [1 2]</span>
<span class="sd">    TRAIN: [0 2] TEST: [1 3]</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;p=</span><span class="si">{}</span><span class="s1"> must be strictly less than the number of &#39;</span>
                <span class="s1">&#39;samples=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">for</span> <span class="n">combination</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">combination</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;X&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">comb</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="n">exact</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">_BaseKFold</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">,</span> <span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for KFold, GroupKFold, and StratifiedKFold&quot;&quot;&quot;</span>

    <span class="nd">@abstractmethod</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="p">,</span> <span class="n">random_state</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The number of folds must be of Integral type. &#39;</span>
                             <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> of type </span><span class="si">%s</span><span class="s1"> was passed.&#39;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">n_splits</span><span class="p">)))</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_splits</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_splits</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;k-fold cross-validation requires at least one&quot;</span>
                <span class="s2">&quot; train/test split by setting n_splits=2 or more,&quot;</span>
                <span class="s2">&quot; got n_splits=</span><span class="si">{0}</span><span class="s2">.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_splits</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">shuffle</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;shuffle must be True or False;&quot;</span>
                            <span class="s2">&quot; got </span><span class="si">{0}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">shuffle</span><span class="p">))</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">shuffle</span> <span class="ow">and</span> <span class="n">random_state</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># None is the default</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Setting a random_state has no effect since shuffle is &#39;</span>
                <span class="s1">&#39;False. You should leave &#39;</span>
                <span class="s1">&#39;random_state to its default (None), or set shuffle=True.&#39;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">n_splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span> <span class="o">=</span> <span class="n">shuffle</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;Cannot have number of splits n_splits=</span><span class="si">{0}</span><span class="s2"> greater&quot;</span>
                 <span class="s2">&quot; than the number of samples: n_samples=</span><span class="si">{1}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>


<span class="k">class</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;K-Folds cross-validator</span>

<span class="sd">    Provides train/test indices to split data in train/test sets. Split</span>
<span class="sd">    dataset into k consecutive folds (without shuffling by default).</span>

<span class="sd">    Each fold is then used once as a validation while the k - 1 remaining</span>
<span class="sd">    folds form the training set.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;k_fold&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``n_splits`` default value changed from 3 to 5.</span>

<span class="sd">    shuffle : bool, default=False</span>
<span class="sd">        Whether to shuffle the data before splitting into batches.</span>
<span class="sd">        Note that the samples within each split will not be shuffled.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        When `shuffle` is True, `random_state` affects the ordering of the</span>
<span class="sd">        indices, which controls the randomness of each fold. Otherwise, this</span>
<span class="sd">        parameter has no effect.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import KFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; kf = KFold(n_splits=2)</span>
<span class="sd">    &gt;&gt;&gt; kf.get_n_splits(X)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(kf)</span>
<span class="sd">    KFold(n_splits=2, random_state=None, shuffle=False)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in kf.split(X):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The first ``n_samples % n_splits`` folds have size</span>
<span class="sd">    ``n_samples // n_splits + 1``, other folds have size</span>
<span class="sd">    ``n_samples // n_splits``, where ``n_samples`` is the number of samples.</span>

<span class="sd">    Randomized CV splitters may return different results for each call of</span>
<span class="sd">    split. You can make the results identical by setting `random_state`</span>
<span class="sd">    to an integer.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    StratifiedKFold : Takes group information into account to avoid building</span>
<span class="sd">        folds with imbalanced class distributions (for binary or multiclass</span>
<span class="sd">        classification tasks).</span>

<span class="sd">    GroupKFold : K-fold iterator variant with non-overlapping groups.</span>

<span class="sd">    RepeatedKFold : Repeats K-Fold n times.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
            <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

        <span class="n">n_splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>
        <span class="n">fold_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="n">n_splits</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">fold_sizes</span><span class="p">[:</span><span class="n">n_samples</span> <span class="o">%</span> <span class="n">n_splits</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">current</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">fold_size</span> <span class="ow">in</span> <span class="n">fold_sizes</span><span class="p">:</span>
            <span class="n">start</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="n">current</span><span class="p">,</span> <span class="n">current</span> <span class="o">+</span> <span class="n">fold_size</span>
            <span class="k">yield</span> <span class="n">indices</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">stop</span><span class="p">]</span>
            <span class="n">current</span> <span class="o">=</span> <span class="n">stop</span>


<span class="k">class</span> <span class="nc">GroupKFold</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;K-fold iterator variant with non-overlapping groups.</span>

<span class="sd">    The same group will not appear in two different folds (the number of</span>
<span class="sd">    distinct groups has to be at least equal to the number of folds).</span>

<span class="sd">    The folds are approximately balanced in the sense that the number of</span>
<span class="sd">    distinct groups is approximately the same in each fold.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;group_k_fold&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``n_splits`` default value changed from 3 to 5.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import GroupKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4])</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([0, 0, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; group_kfold = GroupKFold(n_splits=2)</span>
<span class="sd">    &gt;&gt;&gt; group_kfold.get_n_splits(X, y, groups)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(group_kfold)</span>
<span class="sd">    GroupKFold(n_splits=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in group_kfold.split(X, y, groups):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...     print(X_train, X_test, y_train, y_test)</span>
<span class="sd">    ...</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>
<span class="sd">    [[1 2]</span>
<span class="sd">     [3 4]] [[5 6]</span>
<span class="sd">     [7 8]] [1 2] [3 4]</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    [[5 6]</span>
<span class="sd">     [7 8]] [[1 2]</span>
<span class="sd">     [3 4]] [3 4] [1 2]</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    LeaveOneGroupOut : For splitting the data according to explicit</span>
<span class="sd">        domain-specific stratification of the dataset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_iter_test_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="n">unique_groups</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">n_groups</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">n_groups</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot have number of splits n_splits=</span><span class="si">%d</span><span class="s2"> greater&quot;</span>
                             <span class="s2">&quot; than the number of groups: </span><span class="si">%d</span><span class="s2">.&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">n_groups</span><span class="p">))</span>

        <span class="c1"># Weight groups by their number of occurrences</span>
        <span class="n">n_samples_per_group</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>

        <span class="c1"># Distribute the most frequent groups first</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">n_samples_per_group</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">n_samples_per_group</span> <span class="o">=</span> <span class="n">n_samples_per_group</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

        <span class="c1"># Total weight of each fold</span>
        <span class="n">n_samples_per_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span>

        <span class="c1"># Mapping from group index to fold index</span>
        <span class="n">group_to_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">))</span>

        <span class="c1"># Distribute samples by adding the largest weight to the lightest fold</span>
        <span class="k">for</span> <span class="n">group_index</span><span class="p">,</span> <span class="n">weight</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">n_samples_per_group</span><span class="p">):</span>
            <span class="n">lightest_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">n_samples_per_fold</span><span class="p">)</span>
            <span class="n">n_samples_per_fold</span><span class="p">[</span><span class="n">lightest_fold</span><span class="p">]</span> <span class="o">+=</span> <span class="n">weight</span>
            <span class="n">group_to_fold</span><span class="p">[</span><span class="n">indices</span><span class="p">[</span><span class="n">group_index</span><span class="p">]]</span> <span class="o">=</span> <span class="n">lightest_fold</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">group_to_fold</span><span class="p">[</span><span class="n">groups</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">indices</span> <span class="o">==</span> <span class="n">f</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">StratifiedKFold</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stratified K-Folds cross-validator.</span>

<span class="sd">    Provides train/test indices to split data in train/test sets.</span>

<span class="sd">    This cross-validation object is a variation of KFold that returns</span>
<span class="sd">    stratified folds. The folds are made by preserving the percentage of</span>
<span class="sd">    samples for each class.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;stratified_k_fold&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``n_splits`` default value changed from 3 to 5.</span>

<span class="sd">    shuffle : bool, default=False</span>
<span class="sd">        Whether to shuffle each class&#39;s samples before splitting into batches.</span>
<span class="sd">        Note that the samples within each split will not be shuffled.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        When `shuffle` is True, `random_state` affects the ordering of the</span>
<span class="sd">        indices, which controls the randomness of each fold for each class.</span>
<span class="sd">        Otherwise, leave `random_state` as `None`.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import StratifiedKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; skf = StratifiedKFold(n_splits=2)</span>
<span class="sd">    &gt;&gt;&gt; skf.get_n_splits(X, y)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(skf)</span>
<span class="sd">    StratifiedKFold(n_splits=2, random_state=None, shuffle=False)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in skf.split(X, y):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [1 3] TEST: [0 2]</span>
<span class="sd">    TRAIN: [0 2] TEST: [1 3]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The implementation is designed to:</span>

<span class="sd">    * Generate test sets such that all contain the same distribution of</span>
<span class="sd">      classes, or as close as possible.</span>
<span class="sd">    * Be invariant to class label: relabelling ``y = [&quot;Happy&quot;, &quot;Sad&quot;]`` to</span>
<span class="sd">      ``y = [1, 0]`` should not change the indices generated.</span>
<span class="sd">    * Preserve order dependencies in the dataset ordering, when</span>
<span class="sd">      ``shuffle=False``: all samples from class k in some test set were</span>
<span class="sd">      contiguous in y, or separated in y by samples from classes other than k.</span>
<span class="sd">    * Generate test sets where the smallest and largest differ by at most one</span>
<span class="sd">      sample.</span>

<span class="sd">    .. versionchanged:: 0.22</span>
<span class="sd">        The previous implementation did not follow the last constraint.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    RepeatedStratifiedKFold : Repeats Stratified K-Fold n times.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_make_test_folds</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">type_of_target_y</span> <span class="o">=</span> <span class="n">type_of_target</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">allowed_target_types</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;binary&#39;</span><span class="p">,</span> <span class="s1">&#39;multiclass&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">type_of_target_y</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_target_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;Supported target types are: </span><span class="si">{}</span><span class="s1">. Got </span><span class="si">{!r}</span><span class="s1"> instead.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                    <span class="n">allowed_target_types</span><span class="p">,</span> <span class="n">type_of_target_y</span><span class="p">))</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">y_idx</span><span class="p">,</span> <span class="n">y_inv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_index</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># y_inv encodes y according to lexicographic order. We invert y_idx to</span>
        <span class="c1"># map the classes so that they are encoded by order of appearance:</span>
        <span class="c1"># 0 represents the first label appearing in y, 1 the second, etc.</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">class_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y_idx</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">y_encoded</span> <span class="o">=</span> <span class="n">class_perm</span><span class="p">[</span><span class="n">y_inv</span><span class="p">]</span>

        <span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_idx</span><span class="p">)</span>
        <span class="n">y_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_encoded</span><span class="p">)</span>
        <span class="n">min_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">y_counts</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">y_counts</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;n_splits=</span><span class="si">%d</span><span class="s2"> cannot be greater than the&quot;</span>
                             <span class="s2">&quot; number of members in each class.&quot;</span>
                             <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">&gt;</span> <span class="n">min_groups</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">((</span><span class="s2">&quot;The least populated class in y has only </span><span class="si">%d</span><span class="s2">&quot;</span>
                           <span class="s2">&quot; members, which is less than n_splits=</span><span class="si">%d</span><span class="s2">.&quot;</span>
                           <span class="o">%</span> <span class="p">(</span><span class="n">min_groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)),</span> <span class="ne">UserWarning</span><span class="p">)</span>

        <span class="c1"># Determine the optimal number of samples from each class in each fold,</span>
        <span class="c1"># using round robin over the sorted y. (This can be done direct from</span>
        <span class="c1"># counts, but that code is unreadable.)</span>
        <span class="n">y_order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">y_encoded</span><span class="p">)</span>
        <span class="n">allocation</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span>
            <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_order</span><span class="p">[</span><span class="n">i</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">],</span> <span class="n">minlength</span><span class="o">=</span><span class="n">n_classes</span><span class="p">)</span>
             <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)])</span>

        <span class="c1"># To maintain the data order dependencies as best as possible within</span>
        <span class="c1"># the stratification constraint, we assign samples from each class in</span>
        <span class="c1"># blocks (and then mess that up when shuffle=True).</span>
        <span class="n">test_folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;i&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
            <span class="c1"># since the kth column of allocation stores the number of samples</span>
            <span class="c1"># of class k in each test set, this generates blocks of fold</span>
            <span class="c1"># indices corresponding to the allocation for class k.</span>
            <span class="n">folds_for_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">allocation</span><span class="p">[:,</span> <span class="n">k</span><span class="p">])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">shuffle</span><span class="p">:</span>
                <span class="n">rng</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">folds_for_class</span><span class="p">)</span>
            <span class="n">test_folds</span><span class="p">[</span><span class="n">y_encoded</span> <span class="o">==</span> <span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">folds_for_class</span>
        <span class="k">return</span> <span class="n">test_folds</span>

    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">test_folds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_make_test_folds</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">test_folds</span> <span class="o">==</span> <span class="n">i</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">            Note that providing ``y`` is sufficient to generate the splits and</span>
<span class="sd">            hence ``np.zeros(n_samples)`` may be used as a placeholder for</span>
<span class="sd">            ``X`` instead of actual training data.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>
<span class="sd">            Stratification is done based on the y labels.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">TimeSeriesSplit</span><span class="p">(</span><span class="n">_BaseKFold</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Time Series cross-validator</span>

<span class="sd">    Provides train/test indices to split time series data samples</span>
<span class="sd">    that are observed at fixed time intervals, in train/test sets.</span>
<span class="sd">    In each split, test indices must be higher than before, and thus shuffling</span>
<span class="sd">    in cross validator is inappropriate.</span>

<span class="sd">    This cross-validation object is a variation of :class:`KFold`.</span>
<span class="sd">    In the kth split, it returns first k folds as train set and the</span>
<span class="sd">    (k+1)th fold as test set.</span>

<span class="sd">    Note that unlike standard cross-validation methods, successive</span>
<span class="sd">    training sets are supersets of those that come before them.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;time_series_split&gt;`.</span>

<span class="sd">    .. versionadded:: 0.18</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of splits. Must be at least 2.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``n_splits`` default value changed from 3 to 5.</span>

<span class="sd">    max_train_size : int, default=None</span>
<span class="sd">        Maximum size for a single training set.</span>

<span class="sd">    test_size : int, default=None</span>
<span class="sd">        Used to limit the size of the test set. Defaults to</span>
<span class="sd">        ``n_samples // (n_splits + 1)``, which is the maximum allowed value</span>
<span class="sd">        with ``gap=0``.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">    gap : int, default=0</span>
<span class="sd">        Number of samples to exclude from the end of each train set before</span>
<span class="sd">        the test set.</span>

<span class="sd">        .. versionadded:: 0.24</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import TimeSeriesSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 3, 4, 5, 6])</span>
<span class="sd">    &gt;&gt;&gt; tscv = TimeSeriesSplit()</span>
<span class="sd">    &gt;&gt;&gt; print(tscv)</span>
<span class="sd">    TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in tscv.split(X):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [0] TEST: [1]</span>
<span class="sd">    TRAIN: [0 1] TEST: [2]</span>
<span class="sd">    TRAIN: [0 1 2] TEST: [3]</span>
<span class="sd">    TRAIN: [0 1 2 3] TEST: [4]</span>
<span class="sd">    TRAIN: [0 1 2 3 4] TEST: [5]</span>
<span class="sd">    &gt;&gt;&gt; # Fix test_size to 2 with 12 samples</span>
<span class="sd">    &gt;&gt;&gt; X = np.random.randn(12, 2)</span>
<span class="sd">    &gt;&gt;&gt; y = np.random.randint(0, 2, 12)</span>
<span class="sd">    &gt;&gt;&gt; tscv = TimeSeriesSplit(n_splits=3, test_size=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in tscv.split(X):</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [0 1 2 3 4 5] TEST: [6 7]</span>
<span class="sd">    TRAIN: [0 1 2 3 4 5 6 7] TEST: [8 9]</span>
<span class="sd">    TRAIN: [0 1 2 3 4 5 6 7 8 9] TEST: [10 11]</span>
<span class="sd">    &gt;&gt;&gt; # Add in a 2 period gap</span>
<span class="sd">    &gt;&gt;&gt; tscv = TimeSeriesSplit(n_splits=3, test_size=2, gap=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in tscv.split(X):</span>
<span class="sd">    ...    print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...    X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...    y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [0 1 2 3] TEST: [6 7]</span>
<span class="sd">    TRAIN: [0 1 2 3 4 5] TEST: [8 9]</span>
<span class="sd">    TRAIN: [0 1 2 3 4 5 6 7] TEST: [10 11]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The training set has size ``i * n_samples // (n_splits + 1)</span>
<span class="sd">    + n_samples % (n_splits + 1)`` in the ``i`` th split,</span>
<span class="sd">    with a test set of size ``n_samples//(n_splits + 1)`` by default,</span>
<span class="sd">    where ``n_samples`` is the number of samples.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                 <span class="o">*</span><span class="p">,</span>
                 <span class="n">max_train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">gap</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_train_size</span> <span class="o">=</span> <span class="n">max_train_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="n">test_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gap</span> <span class="o">=</span> <span class="n">gap</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_splits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>
        <span class="n">n_folds</span> <span class="o">=</span> <span class="n">n_splits</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">gap</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gap</span>
        <span class="n">test_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> \
            <span class="k">else</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="n">n_folds</span>

        <span class="c1"># Make sure we have enough samples for the given split parameters</span>
        <span class="k">if</span> <span class="n">n_folds</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Cannot have number of folds=</span><span class="si">{</span><span class="n">n_folds</span><span class="si">}</span><span class="s2"> greater&quot;</span>
                 <span class="sa">f</span><span class="s2">&quot; than the number of samples=</span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">gap</span> <span class="o">-</span> <span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">n_splits</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Too many splits=</span><span class="si">{</span><span class="n">n_splits</span><span class="si">}</span><span class="s2"> for number of samples&quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;=</span><span class="si">{</span><span class="n">n_samples</span><span class="si">}</span><span class="s2"> with test_size=</span><span class="si">{</span><span class="n">test_size</span><span class="si">}</span><span class="s2"> and gap=</span><span class="si">{</span><span class="n">gap</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">))</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
        <span class="n">test_starts</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_splits</span> <span class="o">*</span> <span class="n">test_size</span><span class="p">,</span>
                            <span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">test_start</span> <span class="ow">in</span> <span class="n">test_starts</span><span class="p">:</span>
            <span class="n">train_end</span> <span class="o">=</span> <span class="n">test_start</span> <span class="o">-</span> <span class="n">gap</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_train_size</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_train_size</span> <span class="o">&lt;</span> <span class="n">train_end</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="n">train_end</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_train_size</span><span class="p">:</span><span class="n">train_end</span><span class="p">],</span>
                       <span class="n">indices</span><span class="p">[</span><span class="n">test_start</span><span class="p">:</span><span class="n">test_start</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="p">(</span><span class="n">indices</span><span class="p">[:</span><span class="n">train_end</span><span class="p">],</span>
                       <span class="n">indices</span><span class="p">[</span><span class="n">test_start</span><span class="p">:</span><span class="n">test_start</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">LeaveOneGroupOut</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Leave One Group Out cross-validator</span>

<span class="sd">    Provides train/test indices to split data according to a third-party</span>
<span class="sd">    provided group. This group information can be used to encode arbitrary</span>
<span class="sd">    domain specific stratifications of the samples as integers.</span>

<span class="sd">    For instance the groups could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;leave_one_group_out&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import LeaveOneGroupOut</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([1, 1, 2, 2])</span>
<span class="sd">    &gt;&gt;&gt; logo = LeaveOneGroupOut()</span>
<span class="sd">    &gt;&gt;&gt; logo.get_n_splits(X, y, groups)</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; logo.get_n_splits(groups=groups)  # &#39;groups&#39; is always required</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(logo)</span>
<span class="sd">    LeaveOneGroupOut()</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in logo.split(X, y, groups):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...     print(X_train, X_test, y_train, y_test)</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    [[5 6]</span>
<span class="sd">     [7 8]] [[1 2]</span>
<span class="sd">     [3 4]] [1 2] [1 2]</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>
<span class="sd">    [[1 2]</span>
<span class="sd">     [3 4]] [[5 6]</span>
<span class="sd">     [7 8]] [1 2] [1 2]</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="c1"># We make a copy of groups to avoid side-effects during iteration</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">unique_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The groups parameter contains fewer than 2 unique groups &quot;</span>
                <span class="s2">&quot;(</span><span class="si">%s</span><span class="s2">). LeaveOneGroupOut expects at least 2.&quot;</span> <span class="o">%</span> <span class="n">unique_groups</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">unique_groups</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">groups</span> <span class="o">==</span> <span class="n">i</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set. This &#39;groups&#39; parameter must always be specified to</span>
<span class="sd">            calculate the number of splits, though the other parameters can be</span>
<span class="sd">            omitted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LeavePGroupsOut</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Leave P Group(s) Out cross-validator</span>

<span class="sd">    Provides train/test indices to split data according to a third-party</span>
<span class="sd">    provided group. This group information can be used to encode arbitrary</span>
<span class="sd">    domain specific stratifications of the samples as integers.</span>

<span class="sd">    For instance the groups could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    The difference between LeavePGroupsOut and LeaveOneGroupOut is that</span>
<span class="sd">    the former builds the test sets with all the samples assigned to</span>
<span class="sd">    ``p`` different values of the groups while the latter uses samples</span>
<span class="sd">    all assigned the same groups.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;leave_p_groups_out&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_groups : int</span>
<span class="sd">        Number of groups (``p``) to leave out in the test split.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import LeavePGroupsOut</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 1])</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([1, 2, 3])</span>
<span class="sd">    &gt;&gt;&gt; lpgo = LeavePGroupsOut(n_groups=2)</span>
<span class="sd">    &gt;&gt;&gt; lpgo.get_n_splits(X, y, groups)</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; lpgo.get_n_splits(groups=groups)  # &#39;groups&#39; is always required</span>
<span class="sd">    3</span>
<span class="sd">    &gt;&gt;&gt; print(lpgo)</span>
<span class="sd">    LeavePGroupsOut(n_groups=2)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in lpgo.split(X, y, groups):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...     print(X_train, X_test, y_train, y_test)</span>
<span class="sd">    TRAIN: [2] TEST: [0 1]</span>
<span class="sd">    [[5 6]] [[1 2]</span>
<span class="sd">     [3 4]] [1] [1 2]</span>
<span class="sd">    TRAIN: [1] TEST: [0 2]</span>
<span class="sd">    [[3 4]] [[1 2]</span>
<span class="sd">     [5 6]] [2] [1 1]</span>
<span class="sd">    TRAIN: [0] TEST: [1 2]</span>
<span class="sd">    [[1 2]] [[3 4]</span>
<span class="sd">     [5 6]] [1] [2 1]</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    GroupKFold : K-fold iterator variant with non-overlapping groups.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_groups</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">=</span> <span class="n">n_groups</span>

    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">unique_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The groups parameter contains fewer than (or equal to) &quot;</span>
                <span class="s2">&quot;n_groups (</span><span class="si">%d</span><span class="s2">) numbers of unique groups (</span><span class="si">%s</span><span class="s2">). LeavePGroupsOut &quot;</span>
                <span class="s2">&quot;expects that at least n_groups + 1 (</span><span class="si">%d</span><span class="s2">) unique groups be &quot;</span>
                <span class="s2">&quot;present&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">,</span> <span class="n">unique_groups</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">combi</span> <span class="o">=</span> <span class="n">combinations</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unique_groups</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">indices</span> <span class="ow">in</span> <span class="n">combi</span><span class="p">:</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">unique_groups</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices</span><span class="p">)]:</span>
                <span class="n">test_index</span><span class="p">[</span><span class="n">groups</span> <span class="o">==</span> <span class="n">l</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">yield</span> <span class="n">test_index</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set. This &#39;groups&#39; parameter must always be specified to</span>
<span class="sd">            calculate the number of splits, though the other parameters can be</span>
<span class="sd">            omitted.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="n">comb</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_groups</span><span class="p">,</span> <span class="n">exact</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_RepeatedSplits</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Repeated splits for an arbitrary randomized CV splitter.</span>

<span class="sd">    Repeats splits for cross-validators n times with different randomization</span>
<span class="sd">    in each repetition.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cv : callable</span>
<span class="sd">        Cross-validator class.</span>

<span class="sd">    n_repeats : int, default=10</span>
<span class="sd">        Number of times cross-validator needs to be repeated.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Passes `random_state` to the arbitrary repeating cross validator.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    **cvargs : additional params</span>
<span class="sd">        Constructor parameters for cv. Must not contain random_state</span>
<span class="sd">        and shuffle.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cv</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">cvargs</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of repetitions must be of Integral type.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_repeats</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Number of repetitions must be greater than 0.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">key</span> <span class="ow">in</span> <span class="n">cvargs</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;random_state&#39;</span><span class="p">,</span> <span class="s1">&#39;shuffle&#39;</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;cvargs must not contain random_state or shuffle.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span> <span class="o">=</span> <span class="n">n_repeats</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cvargs</span> <span class="o">=</span> <span class="n">cvargs</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generates indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_repeats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeats</span><span class="p">):</span>
            <span class="n">cv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">cvargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
                <span class="k">yield</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>
<span class="sd">            ``np.zeros(n_samples)`` may be used as a placeholder.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>
<span class="sd">            ``np.zeros(n_samples)`` may be used as a placeholder.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">rng</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">cvargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_repeats</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_build_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">RepeatedKFold</span><span class="p">(</span><span class="n">_RepeatedSplits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Repeated K-Fold cross validator.</span>

<span class="sd">    Repeats K-Fold n times with different randomization in each repetition.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;repeated_k_fold&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">    n_repeats : int, default=10</span>
<span class="sd">        Number of times cross-validator needs to be repeated.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of each repeated cross-validation instance.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import RepeatedKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in rkf.split(X):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...</span>
<span class="sd">    TRAIN: [0 1] TEST: [2 3]</span>
<span class="sd">    TRAIN: [2 3] TEST: [0 1]</span>
<span class="sd">    TRAIN: [1 2] TEST: [0 3]</span>
<span class="sd">    TRAIN: [0 3] TEST: [1 2]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Randomized CV splitters may return different results for each call of</span>
<span class="sd">    split. You can make the results identical by setting `random_state`</span>
<span class="sd">    to an integer.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    RepeatedStratifiedKFold : Repeats Stratified K-Fold n times.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">KFold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">_RepeatedSplits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Repeated Stratified K-Fold cross validator.</span>

<span class="sd">    Repeats Stratified K-Fold n times with different randomization in each</span>
<span class="sd">    repetition.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;repeated_k_fold&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of folds. Must be at least 2.</span>

<span class="sd">    n_repeats : int, default=10</span>
<span class="sd">        Number of times cross-validator needs to be repeated.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the generation of the random states for each repetition.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import RepeatedStratifiedKFold</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,</span>
<span class="sd">    ...     random_state=36851234)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in rskf.split(X, y):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    ...</span>
<span class="sd">    TRAIN: [1 2] TEST: [0 3]</span>
<span class="sd">    TRAIN: [0 3] TEST: [1 2]</span>
<span class="sd">    TRAIN: [1 3] TEST: [0 2]</span>
<span class="sd">    TRAIN: [0 2] TEST: [1 3]</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Randomized CV splitters may return different results for each call of</span>
<span class="sd">    split. You can make the results identical by setting `random_state`</span>
<span class="sd">    to an integer.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    RepeatedKFold : Repeats K-Fold n times.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="n">n_repeats</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">BaseShuffleSplit</span><span class="p">(</span><span class="n">metaclass</span><span class="o">=</span><span class="n">ABCMeta</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Base class for ShuffleSplit and StratifiedShuffleSplit&quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span> <span class="o">=</span> <span class="n">n_splits</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span> <span class="o">=</span> <span class="n">test_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span> <span class="o">=</span> <span class="n">train_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">random_state</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,)</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,), default=None</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_indices</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate (train, test) indices&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">_build_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ShuffleSplit</span><span class="p">(</span><span class="n">BaseShuffleSplit</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Random permutation cross-validator</span>

<span class="sd">    Yields indices to split data into training and test sets.</span>

<span class="sd">    Note: contrary to other cross-validation strategies, random splits</span>
<span class="sd">    do not guarantee that all folds will be different, although this is</span>
<span class="sd">    still very likely for sizeable datasets.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;ShuffleSplit&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=10</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of the dataset to include in the test split. If int, represents the</span>
<span class="sd">        absolute number of test samples. If None, the value is set to the</span>
<span class="sd">        complement of the train size. If ``train_size`` is also None, it will</span>
<span class="sd">        be set to 0.1.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of the training and testing indices produced.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import ShuffleSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([1, 2, 1, 2, 1, 2])</span>
<span class="sd">    &gt;&gt;&gt; rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; rs.get_n_splits(X)</span>
<span class="sd">    5</span>
<span class="sd">    &gt;&gt;&gt; print(rs)</span>
<span class="sd">    ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in rs.split(X):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    TRAIN: [1 3 0 4] TEST: [5 2]</span>
<span class="sd">    TRAIN: [4 0 2 5] TEST: [1 3]</span>
<span class="sd">    TRAIN: [1 2 4 0] TEST: [3 5]</span>
<span class="sd">    TRAIN: [3 4 1 0] TEST: [5 2]</span>
<span class="sd">    TRAIN: [3 5 1 0] TEST: [2 4]</span>
<span class="sd">    &gt;&gt;&gt; rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,</span>
<span class="sd">    ...                   random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in rs.split(X):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    TRAIN: [1 3 0] TEST: [5 2]</span>
<span class="sd">    TRAIN: [4 0 2] TEST: [1 3]</span>
<span class="sd">    TRAIN: [1 2 4] TEST: [3 5]</span>
<span class="sd">    TRAIN: [3 4 1] TEST: [5 2]</span>
<span class="sd">    TRAIN: [3 5 1] TEST: [2 4]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="k">def</span> <span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="n">_validate_shuffle_split</span><span class="p">(</span>
            <span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">default_test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span><span class="p">)</span>

        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="c1"># random partition</span>
            <span class="n">permutation</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
            <span class="n">ind_test</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[:</span><span class="n">n_test</span><span class="p">]</span>
            <span class="n">ind_train</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">n_test</span><span class="p">:(</span><span class="n">n_test</span> <span class="o">+</span> <span class="n">n_train</span><span class="p">)]</span>
            <span class="k">yield</span> <span class="n">ind_train</span><span class="p">,</span> <span class="n">ind_test</span>


<span class="k">class</span> <span class="nc">GroupShuffleSplit</span><span class="p">(</span><span class="n">ShuffleSplit</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Shuffle-Group(s)-Out cross-validation iterator</span>

<span class="sd">    Provides randomized train/test indices to split data according to a</span>
<span class="sd">    third-party provided group. This group information can be used to encode</span>
<span class="sd">    arbitrary domain specific stratifications of the samples as integers.</span>

<span class="sd">    For instance the groups could be the year of collection of the samples</span>
<span class="sd">    and thus allow for cross-validation against time-based splits.</span>

<span class="sd">    The difference between LeavePGroupsOut and GroupShuffleSplit is that</span>
<span class="sd">    the former generates splits using all subsets of size ``p`` unique groups,</span>
<span class="sd">    whereas GroupShuffleSplit generates a user-determined number of random</span>
<span class="sd">    test splits, each with a user-determined fraction of unique groups.</span>

<span class="sd">    For example, a less computationally intensive alternative to</span>
<span class="sd">    ``LeavePGroupsOut(p=10)`` would be</span>
<span class="sd">    ``GroupShuffleSplit(test_size=10, n_splits=100)``.</span>

<span class="sd">    Note: The parameters ``test_size`` and ``train_size`` refer to groups, and</span>
<span class="sd">    not to samples, as in ShuffleSplit.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;group_shuffle_split&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=5</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float, int, default=0.2</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of groups to include in the test split (rounded up). If int,</span>
<span class="sd">        represents the absolute number of test groups. If None, the value is</span>
<span class="sd">        set to the complement of the train size.</span>
<span class="sd">        The default will change in version 0.21. It will remain 0.2 only</span>
<span class="sd">        if ``train_size`` is unspecified, otherwise it will complement</span>
<span class="sd">        the specified ``train_size``.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the groups to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train groups. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of the training and testing indices produced.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import GroupShuffleSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.ones(shape=(8, 2))</span>
<span class="sd">    &gt;&gt;&gt; y = np.ones(shape=(8, 1))</span>
<span class="sd">    &gt;&gt;&gt; groups = np.array([1, 1, 2, 2, 2, 3, 3, 3])</span>
<span class="sd">    &gt;&gt;&gt; print(groups.shape)</span>
<span class="sd">    (8,)</span>
<span class="sd">    &gt;&gt;&gt; gss = GroupShuffleSplit(n_splits=2, train_size=.7, random_state=42)</span>
<span class="sd">    &gt;&gt;&gt; gss.get_n_splits()</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; for train_idx, test_idx in gss.split(X, y, groups):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_idx, &quot;TEST:&quot;, test_idx)</span>
<span class="sd">    TRAIN: [2 3 4 5 6 7] TEST: [0 1]</span>
<span class="sd">    TRAIN: [0 1 5 6 7] TEST: [2 3 4]</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span> <span class="o">=</span> <span class="mf">0.2</span>

    <span class="k">def</span> <span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The &#39;groups&#39; parameter should not be None.&quot;</span><span class="p">)</span>
        <span class="n">groups</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">classes</span><span class="p">,</span> <span class="n">group_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">group_train</span><span class="p">,</span> <span class="n">group_test</span> <span class="ow">in</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_iter_indices</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">classes</span><span class="p">):</span>
            <span class="c1"># these are the indices of classes in the partition</span>
            <span class="c1"># invert them into data indices</span>

            <span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">in1d</span><span class="p">(</span><span class="n">group_indices</span><span class="p">,</span> <span class="n">group_train</span><span class="p">))</span>
            <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flatnonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">in1d</span><span class="p">(</span><span class="n">group_indices</span><span class="p">,</span> <span class="n">group_test</span><span class="p">))</span>

            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">        y : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The target variable for supervised learning problems.</span>

<span class="sd">        groups : array-like of shape (n_samples,)</span>
<span class="sd">            Group labels for the samples used while splitting the dataset into</span>
<span class="sd">            train/test set.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">BaseShuffleSplit</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stratified ShuffleSplit cross-validator</span>

<span class="sd">    Provides train/test indices to split data in train/test sets.</span>

<span class="sd">    This cross-validation object is a merge of StratifiedKFold and</span>
<span class="sd">    ShuffleSplit, which returns stratified randomized folds. The folds</span>
<span class="sd">    are made by preserving the percentage of samples for each class.</span>

<span class="sd">    Note: like the ShuffleSplit strategy, stratified random splits</span>
<span class="sd">    do not guarantee that all folds will be different, although this is</span>
<span class="sd">    still very likely for sizeable datasets.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;stratified_shuffle_split&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    n_splits : int, default=10</span>
<span class="sd">        Number of re-shuffling &amp; splitting iterations.</span>

<span class="sd">    test_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of the dataset to include in the test split. If int, represents the</span>
<span class="sd">        absolute number of test samples. If None, the value is set to the</span>
<span class="sd">        complement of the train size. If ``train_size`` is also None, it will</span>
<span class="sd">        be set to 0.1.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the randomness of the training and testing indices produced.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import StratifiedShuffleSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 0, 1, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)</span>
<span class="sd">    &gt;&gt;&gt; sss.get_n_splits(X, y)</span>
<span class="sd">    5</span>
<span class="sd">    &gt;&gt;&gt; print(sss)</span>
<span class="sd">    StratifiedShuffleSplit(n_splits=5, random_state=0, ...)</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in sss.split(X, y):</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [5 2 3] TEST: [4 1 0]</span>
<span class="sd">    TRAIN: [5 1 4] TEST: [0 2 3]</span>
<span class="sd">    TRAIN: [5 0 2] TEST: [4 3 1]</span>
<span class="sd">    TRAIN: [4 1 0] TEST: [2 3 5]</span>
<span class="sd">    TRAIN: [0 5 1] TEST: [3 4 2]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@_deprecate_positional_args</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span>
            <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span>
            <span class="n">train_size</span><span class="o">=</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="k">def</span> <span class="nf">_iter_indices</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="n">_validate_shuffle_split</span><span class="p">(</span>
            <span class="n">n_samples</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span>
            <span class="n">default_test_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_default_test_size</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># for multi-label y, map each distinct row to a string repr</span>
            <span class="c1"># using join because str(row) uses an ellipsis if len(row) &gt; 1000</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;str&#39;</span><span class="p">))</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">y</span><span class="p">])</span>

        <span class="n">classes</span><span class="p">,</span> <span class="n">y_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">return_inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">n_classes</span> <span class="o">=</span> <span class="n">classes</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">class_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_indices</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">class_counts</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The least populated class in y has only 1&quot;</span>
                             <span class="s2">&quot; member, which is too few. The minimum&quot;</span>
                             <span class="s2">&quot; number of groups for any class cannot&quot;</span>
                             <span class="s2">&quot; be less than 2.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">n_train</span> <span class="o">&lt;</span> <span class="n">n_classes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The train_size = </span><span class="si">%d</span><span class="s1"> should be greater or &#39;</span>
                             <span class="s1">&#39;equal to the number of classes = </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">n_test</span> <span class="o">&lt;</span> <span class="n">n_classes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The test_size = </span><span class="si">%d</span><span class="s1"> should be greater or &#39;</span>
                             <span class="s1">&#39;equal to the number of classes = </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span>
                             <span class="p">(</span><span class="n">n_test</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>

        <span class="c1"># Find the sorted list of instances for each class:</span>
        <span class="c1"># (np.unique above performs a sort, so code is O(n logn) already)</span>
        <span class="n">class_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">y_indices</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s1">&#39;mergesort&#39;</span><span class="p">),</span>
                                 <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">class_counts</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="n">rng</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_splits</span><span class="p">):</span>
            <span class="c1"># if there are ties in the class-counts, we want</span>
            <span class="c1"># to make sure to break them anew in each iteration</span>
            <span class="n">n_i</span> <span class="o">=</span> <span class="n">_approximate_mode</span><span class="p">(</span><span class="n">class_counts</span><span class="p">,</span> <span class="n">n_train</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>
            <span class="n">class_counts_remaining</span> <span class="o">=</span> <span class="n">class_counts</span> <span class="o">-</span> <span class="n">n_i</span>
            <span class="n">t_i</span> <span class="o">=</span> <span class="n">_approximate_mode</span><span class="p">(</span><span class="n">class_counts_remaining</span><span class="p">,</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

            <span class="n">train</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">test</span> <span class="o">=</span> <span class="p">[]</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">):</span>
                <span class="n">permutation</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">class_counts</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                <span class="n">perm_indices_class_i</span> <span class="o">=</span> <span class="n">class_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">permutation</span><span class="p">,</span>
                                                             <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;clip&#39;</span><span class="p">)</span>

                <span class="n">train</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">perm_indices_class_i</span><span class="p">[:</span><span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
                <span class="n">test</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">perm_indices_class_i</span><span class="p">[</span><span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span><span class="n">n_i</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">t_i</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>

            <span class="n">train</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
            <span class="n">test</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : array-like of shape (n_samples, n_features)</span>
<span class="sd">            Training data, where n_samples is the number of samples</span>
<span class="sd">            and n_features is the number of features.</span>

<span class="sd">            Note that providing ``y`` is sufficient to generate the splits and</span>
<span class="sd">            hence ``np.zeros(n_samples)`` may be used as a placeholder for</span>
<span class="sd">            ``X`` instead of actual training data.</span>

<span class="sd">        y : array-like of shape (n_samples,) or (n_samples, n_labels)</span>
<span class="sd">            The target variable for supervised learning problems.</span>
<span class="sd">            Stratification is done based on the y labels.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Randomized CV splitters may return different results for each call of</span>
<span class="sd">        split. You can make the results identical by setting `random_state`</span>
<span class="sd">        to an integer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_validate_shuffle_split</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span>
                            <span class="n">default_test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Validation helper to check if the test/test sizes are meaningful wrt to the</span>
<span class="sd">    size of the data (n_samples)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">test_size</span> <span class="o">=</span> <span class="n">default_test_size</span>

    <span class="n">test_size_type</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span>
    <span class="n">train_size_type</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">kind</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">test_size_type</span> <span class="o">==</span> <span class="s1">&#39;i&#39;</span> <span class="ow">and</span> <span class="p">(</span><span class="n">test_size</span> <span class="o">&gt;=</span> <span class="n">n_samples</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
       <span class="ow">or</span> <span class="n">test_size_type</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span> <span class="ow">and</span> <span class="p">(</span><span class="n">test_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">test_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;test_size=</span><span class="si">{0}</span><span class="s1"> should be either positive and smaller&#39;</span>
                         <span class="s1">&#39; than the number of samples </span><span class="si">{1}</span><span class="s1"> or a float in the &#39;</span>
                         <span class="s1">&#39;(0, 1) range&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">train_size_type</span> <span class="o">==</span> <span class="s1">&#39;i&#39;</span> <span class="ow">and</span> <span class="p">(</span><span class="n">train_size</span> <span class="o">&gt;=</span> <span class="n">n_samples</span> <span class="ow">or</span> <span class="n">train_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">)</span>
       <span class="ow">or</span> <span class="n">train_size_type</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span> <span class="ow">and</span> <span class="p">(</span><span class="n">train_size</span> <span class="o">&lt;=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">train_size</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;train_size=</span><span class="si">{0}</span><span class="s1"> should be either positive and smaller&#39;</span>
                         <span class="s1">&#39; than the number of samples </span><span class="si">{1}</span><span class="s1"> or a float in the &#39;</span>
                         <span class="s1">&#39;(0, 1) range&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_size</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">train_size_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;f&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid value for train_size: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_size</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">test_size_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;f&#39;</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Invalid value for test_size: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_size</span><span class="p">))</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">train_size_type</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span> <span class="ow">and</span> <span class="n">test_size_type</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span> <span class="ow">and</span>
            <span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;The sum of test_size and train_size = </span><span class="si">{}</span><span class="s1">, should be in the (0, 1)&#39;</span>
            <span class="s1">&#39; range. Reduce test_size and/or train_size.&#39;</span>
            <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_size</span> <span class="o">+</span> <span class="n">test_size</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">test_size_type</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">test_size_type</span> <span class="o">==</span> <span class="s1">&#39;i&#39;</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">test_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">train_size_type</span> <span class="o">==</span> <span class="s1">&#39;f&#39;</span><span class="p">:</span>
        <span class="n">n_train</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">train_size</span> <span class="o">*</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">train_size_type</span> <span class="o">==</span> <span class="s1">&#39;i&#39;</span><span class="p">:</span>
        <span class="n">n_train</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">train_size</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">train_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_train</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_test</span>
    <span class="k">elif</span> <span class="n">test_size</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">n_test</span> <span class="o">=</span> <span class="n">n_samples</span> <span class="o">-</span> <span class="n">n_train</span>

    <span class="k">if</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span> <span class="o">&gt;</span> <span class="n">n_samples</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The sum of train_size and test_size = </span><span class="si">%d</span><span class="s1">, &#39;</span>
                         <span class="s1">&#39;should be smaller than the number of &#39;</span>
                         <span class="s1">&#39;samples </span><span class="si">%d</span><span class="s1">. Reduce test_size and/or &#39;</span>
                         <span class="s1">&#39;train_size.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">))</span>

    <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_train</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_test</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">n_train</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;With n_samples=</span><span class="si">{}</span><span class="s1">, test_size=</span><span class="si">{}</span><span class="s1"> and train_size=</span><span class="si">{}</span><span class="s1">, the &#39;</span>
            <span class="s1">&#39;resulting train set will be empty. Adjust any of the &#39;</span>
            <span class="s1">&#39;aforementioned parameters.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span>
                                                <span class="n">train_size</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span>


<span class="k">class</span> <span class="nc">PredefinedSplit</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Predefined split cross-validator</span>

<span class="sd">    Provides train/test indices to split data into train/test sets using a</span>
<span class="sd">    predefined scheme specified by the user with the ``test_fold`` parameter.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;predefined_split&gt;`.</span>

<span class="sd">    .. versionadded:: 0.16</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    test_fold : array-like of shape (n_samples,)</span>
<span class="sd">        The entry ``test_fold[i]`` represents the index of the test set that</span>
<span class="sd">        sample ``i`` belongs to. It is possible to exclude sample ``i`` from</span>
<span class="sd">        any test set (i.e. include sample ``i`` in every training set) by</span>
<span class="sd">        setting ``test_fold[i]`` equal to -1.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import PredefinedSplit</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])</span>
<span class="sd">    &gt;&gt;&gt; y = np.array([0, 0, 1, 1])</span>
<span class="sd">    &gt;&gt;&gt; test_fold = [0, 1, -1, 1]</span>
<span class="sd">    &gt;&gt;&gt; ps = PredefinedSplit(test_fold)</span>
<span class="sd">    &gt;&gt;&gt; ps.get_n_splits()</span>
<span class="sd">    2</span>
<span class="sd">    &gt;&gt;&gt; print(ps)</span>
<span class="sd">    PredefinedSplit(test_fold=array([ 0,  1, -1,  1]))</span>
<span class="sd">    &gt;&gt;&gt; for train_index, test_index in ps.split():</span>
<span class="sd">    ...     print(&quot;TRAIN:&quot;, train_index, &quot;TEST:&quot;, test_index)</span>
<span class="sd">    ...     X_train, X_test = X[train_index], X[test_index]</span>
<span class="sd">    ...     y_train, y_test = y[train_index], y[test_index]</span>
<span class="sd">    TRAIN: [1 2 3] TEST: [0]</span>
<span class="sd">    TRAIN: [0 2] TEST: [1 3]</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">test_fold</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_fold</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_test_masks</span><span class="p">():</span>
            <span class="n">train_index</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">logical_not</span><span class="p">(</span><span class="n">test_index</span><span class="p">)]</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">ind</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
            <span class="k">yield</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span>

    <span class="k">def</span> <span class="nf">_iter_test_masks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generates boolean masks corresponding to test sets.&quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">:</span>
            <span class="n">test_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span> <span class="o">==</span> <span class="n">f</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">test_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_fold</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
            <span class="n">test_mask</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">yield</span> <span class="n">test_mask</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">unique_folds</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_CVIterableWrapper</span><span class="p">(</span><span class="n">BaseCrossValidator</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper class for old style cv objects and iterables.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cv</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_n_splits</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the number of splitting iterations in the cross-validator</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        n_splits : int</span>
<span class="sd">            Returns the number of splitting iterations in the cross-validator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Generate indices to split data into training and test set.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        y : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        groups : object</span>
<span class="sd">            Always ignored, exists for compatibility.</span>

<span class="sd">        Yields</span>
<span class="sd">        ------</span>
<span class="sd">        train : ndarray</span>
<span class="sd">            The training set indices for that split.</span>

<span class="sd">        test : ndarray</span>
<span class="sd">            The testing set indices for that split.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>


<span class="nd">@_deprecate_positional_args</span>
<span class="k">def</span> <span class="nf">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Input checker utility for building a cross-validator</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    cv : int, cross-validation generator or an iterable, default=None</span>
<span class="sd">        Determines the cross-validation splitting strategy.</span>
<span class="sd">        Possible inputs for cv are:</span>
<span class="sd">        - None, to use the default 5-fold cross validation,</span>
<span class="sd">        - integer, to specify the number of folds.</span>
<span class="sd">        - :term:`CV splitter`,</span>
<span class="sd">        - An iterable yielding (train, test) splits as arrays of indices.</span>

<span class="sd">        For integer/None inputs, if classifier is True and ``y`` is either</span>
<span class="sd">        binary or multiclass, :class:`StratifiedKFold` is used. In all other</span>
<span class="sd">        cases, :class:`KFold` is used.</span>

<span class="sd">        Refer :ref:`User Guide &lt;cross_validation&gt;` for the various</span>
<span class="sd">        cross-validation strategies that can be used here.</span>

<span class="sd">        .. versionchanged:: 0.22</span>
<span class="sd">            ``cv`` default value changed from 3-fold to 5-fold.</span>

<span class="sd">    y : array-like, default=None</span>
<span class="sd">        The target variable for supervised learning problems.</span>

<span class="sd">    classifier : bool, default=False</span>
<span class="sd">        Whether the task is a classification task, in which case</span>
<span class="sd">        stratified KFold will be used.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    checked_cv : a cross-validator instance.</span>
<span class="sd">        The return value is a cross-validator which generates the train/test</span>
<span class="sd">        splits via the ``split`` method.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cv</span> <span class="o">=</span> <span class="mi">5</span> <span class="k">if</span> <span class="n">cv</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">cv</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">):</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">classifier</span> <span class="ow">and</span> <span class="p">(</span><span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span>
                <span class="p">(</span><span class="n">type_of_target</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;binary&#39;</span><span class="p">,</span> <span class="s1">&#39;multiclass&#39;</span><span class="p">))):</span>
            <span class="k">return</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">KFold</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="s1">&#39;split&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Expected cv as an integer, cross-validation &quot;</span>
                             <span class="s2">&quot;object (from sklearn.model_selection) &quot;</span>
                             <span class="s2">&quot;or an iterable. Got </span><span class="si">%s</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="n">cv</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_CVIterableWrapper</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">cv</span>  <span class="c1"># New style cv objects are passed without any modification</span>


<span class="k">def</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="o">*</span><span class="n">arrays</span><span class="p">,</span>
                     <span class="n">test_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">train_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                     <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">stratify</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Split arrays or matrices into random train and test subsets</span>

<span class="sd">    Quick utility that wraps input validation and</span>
<span class="sd">    ``next(ShuffleSplit().split(X, y))`` and application to input data</span>
<span class="sd">    into a single call for splitting (and optionally subsampling) data in a</span>
<span class="sd">    oneliner.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    *arrays : sequence of indexables with same length / shape[0]</span>
<span class="sd">        Allowed inputs are lists, numpy arrays, scipy-sparse</span>
<span class="sd">        matrices or pandas dataframes.</span>

<span class="sd">    test_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the proportion</span>
<span class="sd">        of the dataset to include in the test split. If int, represents the</span>
<span class="sd">        absolute number of test samples. If None, the value is set to the</span>
<span class="sd">        complement of the train size. If ``train_size`` is also None, it will</span>
<span class="sd">        be set to 0.25.</span>

<span class="sd">    train_size : float or int, default=None</span>
<span class="sd">        If float, should be between 0.0 and 1.0 and represent the</span>
<span class="sd">        proportion of the dataset to include in the train split. If</span>
<span class="sd">        int, represents the absolute number of train samples. If None,</span>
<span class="sd">        the value is automatically set to the complement of the test size.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Controls the shuffling applied to the data before applying the split.</span>
<span class="sd">        Pass an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>


<span class="sd">    shuffle : bool, default=True</span>
<span class="sd">        Whether or not to shuffle the data before splitting. If shuffle=False</span>
<span class="sd">        then stratify must be None.</span>

<span class="sd">    stratify : array-like, default=None</span>
<span class="sd">        If not None, data is split in a stratified fashion, using this as</span>
<span class="sd">        the class labels.</span>
<span class="sd">        Read more in the :ref:`User Guide &lt;stratification&gt;`.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    splitting : list, length=2 * len(arrays)</span>
<span class="sd">        List containing train-test split of inputs.</span>

<span class="sd">        .. versionadded:: 0.16</span>
<span class="sd">            If the input is sparse, the output will be a</span>
<span class="sd">            ``scipy.sparse.csr_matrix``. Else, output type is the same as the</span>
<span class="sd">            input type.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.model_selection import train_test_split</span>
<span class="sd">    &gt;&gt;&gt; X, y = np.arange(10).reshape((5, 2)), range(5)</span>
<span class="sd">    &gt;&gt;&gt; X</span>
<span class="sd">    array([[0, 1],</span>
<span class="sd">           [2, 3],</span>
<span class="sd">           [4, 5],</span>
<span class="sd">           [6, 7],</span>
<span class="sd">           [8, 9]])</span>
<span class="sd">    &gt;&gt;&gt; list(y)</span>
<span class="sd">    [0, 1, 2, 3, 4]</span>

<span class="sd">    &gt;&gt;&gt; X_train, X_test, y_train, y_test = train_test_split(</span>
<span class="sd">    ...     X, y, test_size=0.33, random_state=42)</span>
<span class="sd">    ...</span>
<span class="sd">    &gt;&gt;&gt; X_train</span>
<span class="sd">    array([[4, 5],</span>
<span class="sd">           [0, 1],</span>
<span class="sd">           [6, 7]])</span>
<span class="sd">    &gt;&gt;&gt; y_train</span>
<span class="sd">    [2, 0, 3]</span>
<span class="sd">    &gt;&gt;&gt; X_test</span>
<span class="sd">    array([[2, 3],</span>
<span class="sd">           [8, 9]])</span>
<span class="sd">    &gt;&gt;&gt; y_test</span>
<span class="sd">    [1, 4]</span>

<span class="sd">    &gt;&gt;&gt; train_test_split(y, shuffle=False)</span>
<span class="sd">    [[0, 1, 2], [3, 4]]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_arrays</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">arrays</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_arrays</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;At least one array required as input&quot;</span><span class="p">)</span>

    <span class="n">arrays</span> <span class="o">=</span> <span class="n">indexable</span><span class="p">(</span><span class="o">*</span><span class="n">arrays</span><span class="p">)</span>

    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">_num_samples</span><span class="p">(</span><span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">n_train</span><span class="p">,</span> <span class="n">n_test</span> <span class="o">=</span> <span class="n">_validate_shuffle_split</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">train_size</span><span class="p">,</span>
                                              <span class="n">default_test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">shuffle</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">stratify</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Stratified train/test split is not implemented for &quot;</span>
                <span class="s2">&quot;shuffle=False&quot;</span><span class="p">)</span>

        <span class="n">train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">)</span>
        <span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_train</span><span class="p">,</span> <span class="n">n_train</span> <span class="o">+</span> <span class="n">n_test</span><span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">stratify</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">CVClass</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">CVClass</span> <span class="o">=</span> <span class="n">ShuffleSplit</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="n">CVClass</span><span class="p">(</span><span class="n">test_size</span><span class="o">=</span><span class="n">n_test</span><span class="p">,</span>
                     <span class="n">train_size</span><span class="o">=</span><span class="n">n_train</span><span class="p">,</span>
                     <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>

        <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">arrays</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">stratify</span><span class="p">))</span>

    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">from_iterable</span><span class="p">((</span><span class="n">_safe_indexing</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">train</span><span class="p">),</span>
                                     <span class="n">_safe_indexing</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">arrays</span><span class="p">))</span>


<span class="c1"># Tell nose that train_test_split is not a test.</span>
<span class="c1"># (Needed for external libraries that may use nose.)</span>
<span class="c1"># Use setattr to avoid mypy errors when monkeypatching.</span>
<span class="nb">setattr</span><span class="p">(</span><span class="n">train_test_split</span><span class="p">,</span> <span class="s1">&#39;__test__&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_build_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># XXX This is copied from BaseEstimator&#39;s get_params</span>
    <span class="bp">cls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span>
    <span class="n">init</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">,</span> <span class="s1">&#39;deprecated_original&#39;</span><span class="p">,</span> <span class="bp">cls</span><span class="o">.</span><span class="fm">__init__</span><span class="p">)</span>
    <span class="c1"># Ignore varargs, kw and default values and pop self</span>
    <span class="n">init_signature</span> <span class="o">=</span> <span class="n">signature</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
    <span class="c1"># Consider the constructor parameters excluding &#39;self&#39;</span>
    <span class="k">if</span> <span class="n">init</span> <span class="ow">is</span> <span class="nb">object</span><span class="o">.</span><span class="fm">__init__</span><span class="p">:</span>
        <span class="n">args</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">args</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">init_signature</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>
                       <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">name</span> <span class="o">!=</span> <span class="s1">&#39;self&#39;</span> <span class="ow">and</span> <span class="n">p</span><span class="o">.</span><span class="n">kind</span> <span class="o">!=</span> <span class="n">p</span><span class="o">.</span><span class="n">VAR_KEYWORD</span><span class="p">])</span>
    <span class="n">class_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">args</span><span class="p">:</span>
        <span class="c1"># We need deprecation warnings to always be on in order to</span>
        <span class="c1"># catch deprecated param values.</span>
        <span class="c1"># This is set in utils/__init__.py but it gets overwritten</span>
        <span class="c1"># when running under python3 somehow.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;always&quot;</span><span class="p">,</span> <span class="ne">FutureWarning</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">as</span> <span class="n">w</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;cvargs&#39;</span><span class="p">):</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cvargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">category</span> <span class="o">==</span> <span class="ne">FutureWarning</span><span class="p">:</span>
                <span class="c1"># if the parameter is deprecated, don&#39;t show it</span>
                <span class="k">continue</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filters</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

    <span class="k">return</span> <span class="s1">&#39;</span><span class="si">%s</span><span class="s1">(</span><span class="si">%s</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">class_name</span><span class="p">,</span> <span class="n">_pprint</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">class_name</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">_yields_constant_splits</span><span class="p">(</span><span class="n">cv</span><span class="p">):</span>
    <span class="c1"># Return True if calling cv.split() always returns the same splits</span>
    <span class="c1"># We assume that if a cv doesn&#39;t have a shuffle parameter, it shuffles by</span>
    <span class="c1"># default (e.g. ShuffleSplit). If it actually doesn&#39;t shuffle (e.g.</span>
    <span class="c1"># LeaveOneOut), then it won&#39;t have a random_state parameter anyway, in</span>
    <span class="c1"># which case it will default to 0, leading to output=True</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="s1">&#39;shuffle&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">random_state</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="s1">&#39;random_state&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">random_state</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Integral</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">shuffle</span>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, LinkedIn

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

  

  <script type="text/javascript" src="../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>