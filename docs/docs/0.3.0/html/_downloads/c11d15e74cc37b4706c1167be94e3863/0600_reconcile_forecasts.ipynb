{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Reconcile Forecasts\n\nThis tutorial explains how use the\n`~greykite.algo.reconcile.convex.reconcile_forecasts.ReconcileAdditiveForecasts`\nclass to create forecasts that satisfy inter-forecast additivity constraints.\n\nThe inputs are:\n\n1. additive constraints to be satisfied\n2. original (base) forecasts (timeseries)\n3. actuals (timeseries)\n\nThe output is adjusted forecasts that satisfy the constraints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimization Approach\nThe adjusted forecasts are computed as a linear transformation of the base forecasts.\nThe linear transform is the solution to an optimization problem\n(`details <../../pages/miscellaneous/reconcile_forecasts>`_).\n\nIn brief, the objective is to minimize the weighted sum of these error terms:\n\n1. ``Training MSE``: empirical MSE of the adjusted forecasts on the training set\n2. ``Bias penalty``: estimated squared bias of adjusted forecast errors\n3. ``Variance penalty``: estimated variance of adjusted forecast errors for an unbiased\n   transformation, assuming base forecasts are unbiased (this underestimates the variance\n   if the transformation is biased).\n4. ``Adjustment penalty``: regularization term that penalizes large adjustments\n\nSubject to these constraints:\n\n1. Adjusted forecasts satisfy inter-forecast additivity constraints (required)\n2. Transform is unbiased (optional)\n3. Transform matrix entries are between [lower, upper] bound (optional)\n\n`~greykite.algo.reconcile.convex.reconcile_forecasts.ReconcileAdditiveForecasts`\nallows you to tune the optimization objective and constraints.\nIt also exposes common methods as special cases of this optimization problem.\nThe available methods are:\n\n* ``\"bottom_up\"`` (bottom up)\n* ``\"ols\"`` (`OLS <https://robjhyndman.com/papers/Hierarchical6.pdf>`_)\n* ``\"mint_sample\"`` (`MinT <https://robjhyndman.com/papers/mint.pdf>`_ with sample covariance)\n* ``\"custom\"`` (custom objective and constraints)\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>``\"bottom_up\"`` is applicable when the constraints can be represented as a tree.\n  It produces reconciled forecasts by summing the leaf nodes. This is equivalent to the\n  solution to the optimization that only penalizes adjustment to the leaf nodes' forecasts.\n\n  ``\"ols\"`` and ``\"mint_sample\"`` include only the variance penalty and require\n  that the transform be unbiased. The variance penalty depends on forecast error covariances.\n  ``\"ols\"`` assumes base forecast errors are uncorrelated with equal variance.\n  ``\"mint_sample\"`` uses sample covariance of the forecast errors.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Input Data\nIn this tutorial, we consider a 3-level tree with the parent-child relationships below.\n\n.. code-block:: none\n\n          00        # level 0\n        /   \\\n     10       11    # level 1\n    / | \\     /\\\n  20 21 22   23 24  # level 2\n\nWe want the forecasts of parent nodes to equal the sum of the forecasts of their children.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need to generate forecasts for each of the nodes.\nOne approach is to generate the forecasts independently, using rolling window\nforecasting to get h-step ahead forecasts over time, for some constant ``h``.\nThis can be done with the :doc:`benchmark class </gallery/tutorials/0300_benchmark>`.\n(The variance penalty assumes the residuals have fixed covariance,\nand using constant ``h`` helps with that assumption.)\n\nFor this tutorial, we assume that forecasts have already been computed.\nBelow, ``forecasts`` and ``actuals`` are pandas DataFrames in long format, where each column\nis a time series, and each row is a time step. The rows are sorted in ascending order.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport plotly\nimport warnings\n\nimport pandas as pd\nimport numpy as np\n\nfrom greykite.algo.reconcile.convex.reconcile_forecasts import ReconcileAdditiveForecasts\nfrom greykite.common.constants import TIME_COL\nfrom greykite.common.data_loader import DataLoader\nfrom greykite.common.viz.timeseries_plotting import plot_multivariate\n\nlogger = logging.getLogger()\nlogger.setLevel(logging.ERROR)  # reduces logging\nwarnings.simplefilter(\"ignore\", category=UserWarning)  # ignores matplotlib warnings when rendering documentation\n\ndl = DataLoader()\nactuals = dl.load_data(data_name=\"daily_hierarchical_actuals\")\nforecasts = dl.load_data(data_name=\"daily_hierarchical_forecasts\")\nactuals.set_index(TIME_COL, inplace=True)\nforecasts.set_index(TIME_COL, inplace=True)\nforecasts.head().round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To use the reconcile method, dataframe columns should contain\n  only the forecasts or actuals timeseries. Time should\n  not be its own column.\n\n  Above, we set time as the index using ``.set_index()``.\n  Index values are ignored by the reconcile method\n  so you could also choose to drop the column.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The rows and columns in forecasts and actuals correspond to each other.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert forecasts.index.equals(actuals.index)\nassert forecasts.columns.equals(actuals.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we need to encode the constraints.\nIn general, these can be defined by ``constraint_matrix``.\nThis is a ``c x m`` array encoding ``c`` constraints in ``m`` variables,\nwhere ``m`` is the number of timeseries. The columns in this matrix\ncorrespond to the columns in the forecasts/actuals dataframes below.\nThe rows encode additive expressions that must equal 0.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "constraint_matrix = np.array([\n   # 00  10  11 20 21 22 23 24\n    [-1,  1,  1, 0, 0, 0, 0, 0],  # 0 = -1*x_00 + 1*x_10 + 1*x_11\n    [ 0, -1,  0, 1, 1, 1, 0, 0],  # 0 = -1*x_10 + 1*x_20 + 1*x_21 + 1*x_22\n    [ 0,  0, -1, 0, 0, 0, 1, 1]   # 0 = -1*x_11 + 1*x_23 + 1*x_24\n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, if the graph is a tree, you can use the ``levels`` parameter. This\nis a more concise way to specify additive tree # constraints, where forecasts of\nparent nodes must equal the sum of the forecasts of their children. It assumes\nthe columns in ``forecasts`` and ``actuals`` are in the tree's breadth first\ntraversal order: i.e., starting from the root, scan left to right,\ntop to bottom, as shown below for our example:\n\n.. code-block:: none\n\n          0\n       /     \\\n      1       2\n    / | \\    / \\\n   3  4  5  6   7\n\nHere is an equivalent specification using the ``levels`` parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The root has two children.\n# Its children have 3 and 2 children, respectively.\nlevels = [[2], [3, 2]]\n# Summarize non-leaf nodes by the number of children\n# they have, and iterate in breadth first traversal order.\n# Each level in the tree becomes a sublist of `levels`.\n#\n#          (2)     --> [2]\n#         /   \\\n#      (3)     (2) --> [3, 2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>More formally, ``levels`` specifies the number of children of each\n  internal node in the tree. The ith inner list provides the number\n  of children of each node in level i. Thus, the first sublist has one\n  integer, the length of a sublist is the sum of the previous sublist,\n  and all entries in ``levels`` are positive integers.\n  All leaf nodes must have the same depth.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For illustration, we plot the inconsistency between forecasts\nof the root node, ``\"00\"``, and its children.\nNotice that the blue and orange lines do not perfectly overlap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parent = \"00\"\nchildren = [\"10\", \"11\"]\ncols = {\n    f\"parent-{parent}\": forecasts[parent],\n    \"sum(children)\": sum(forecasts[child] for child in children)\n}\ncols.update({f\"child-{child}\": forecasts[child] for child in children})\ncols[TIME_COL] = forecasts.index\nparent_child_df = pd.DataFrame(cols)\nfig = plot_multivariate(\n    df=parent_child_df,\n    x_col=TIME_COL,\n    title=f\"Forecasts of node '{parent}' and its children violate the constraint\",\n)\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Forecast reconciliation\n\n### Training Evaluation\nTo reconcile these forecasts, we use the\n`~greykite.algo.reconcile.convex.reconcile_forecasts.ReconcileAdditiveForecasts` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf = ReconcileAdditiveForecasts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit\nCall ``fit()`` to learn the linear transform.\nAvailable methods are ``\"bottom_up\"``, ``\"ols\"``,\n``\"mint_sample\"``, ``\"custom\"``.\nLet's start with the bottom up method.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = raf.fit(\n    forecasts=forecasts,\n    actuals=actuals,\n    levels=levels,\n    method=\"bottom_up\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Each row in the transform matrix shows how to compute\nthe adjusted forecast as a linear combination of the base forecasts.\nFor the \"bottom up\" transform, the matrix simply reflects the tree structure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.transform_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize this matrix to more easily see how forecasts are combined.\nThe top row in this plot shows that the adjusted forecast for\nnode \"00\" (tree root) is the sum of all the base forecasts of the leaf nodes.\n\"10\" and \"11\" are the sum of their children, and each leaf node keeps its original value.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = raf.plot_transform_matrix()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Transform\nThe ``transform()`` method applies the transform and returns the adjusted (consistent) forecasts.\nIf we call it without arguments, it applies the transform to the training set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adjusted_forecasts = raf.transform()\nadjusted_forecasts.head().round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The adjusted forecasts on the training set are stored in the ``adjusted_forecasts`` attribute.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert adjusted_forecasts.equals(raf.adjusted_forecasts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate\nNow that we have the actuals, forecasts, and adjusted forecasts,\nwe can check how the adjustment affects forecast quality.\nHere, we do evaluation on the training set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = raf.evaluate(\n    is_train=True,         # evaluates on training set\n    ipython_display=True,  # displays evaluation table\n    plot=True,             # displays plots\n    plot_num_cols=2,       # formats plots into two columns\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For better formatting in this documentation, let's display the\ntable again. ``evaluation_df`` contains the\nevaluation table for the training set. The errors for\nthe leaf nodes are the same, as expected, because their\nforecasts have not changed.\nThe error for nodes \"00\" and \"11\" have increased.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.evaluation_df.round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The ``ipython_display`` parameter controls whether to display the evaluation table.\n\n  - The \"\\*change\" columns show the change in error after adjustment.\n  - The \"Base\\*\" columns show evaluation metrics for the original base forecasts.\n  - The \"Adjusted\\*\" columns show evaluation metrics for the adjusted forecasts.\n  - MAPE/MedAPE = mean/median absolute percentage error,\n    RMSE = root mean squared error, pp = percentage point.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can check the diagnostic plots for more information.\nThe \"Base vs Adjusted\" and \"Adjustment Size\" plots show that\nthe forecasts for \"00\" and \"11\" are higher after adjustment.\nThe \"Forecast Error\" plot shows that this increased the forecast error.\n(Plots are automatically shown when ``plot=True``.\nTo make plots appear inline in this tutorial, we need\nto explicitly show the figures.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotly.io.show(raf.figures[\"base_adj\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotly.io.show(raf.figures[\"adj_size\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotly.io.show(raf.figures[\"error\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The ``plot`` parameter controls whether to display\n  diagnostic plots to adjusted to base forecasts.\n\n  - \"Base vs Adjusted Forecast\" shows base forecast (blue) vs adjusted forecast (orange)\n  - \"Adjustment Size (%)\" shows the size of the adjustment.\n  - \"Forecast Error (%)\" shows the % error before (blue) and after (orange) adjustment.\n    Closer to 0 is better.\n  - Note that the y-axes are independent.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For completeness, we can verify that the actuals\nand adjusted forecasts satisfy the constraints.\n``constraint_violation`` shows constraint violation on the training set,\ndefined as root mean squared violation\n(averaged across time points and constraints),\ndivided by root mean squared actual value.\nIt should be close to 0 for \"adjusted\" and \"actual\".\n(This is not necessary to check, because\na warning is printed during fitting if actuals do not satisfy the constraints\nor if there is no solution to the optimization problem.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.constraint_violation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Set Evaluation\nEvaluation on the training set is sufficient for the ``\"bottom_up\"``\nand ``\"ols\"`` methods, because they do not use the forecasts or actuals\nto learn the transform matrix. The transform depends only on the constraints.\n\nThe ``\"mint_sample\"`` and ``\"custom\"`` methods use forecasts and actuals\nin addition to the constraints, so we should evaluate accuracy\non an out-of-sample test set.\n\n.. csv-table:: Information used by each method\n   :header: \"\", \"constraints\", \"forecasts\", \"actuals\"\n\n   \"``bottom_up``\", \"X\", \"\", \"\"\n   \"``ols``\", \"X\", \"\", \"\"\n   \"``mint_sample``\", \"X\", \"X\", \"X\"\n   \"``custom``\", \"X\", \"X\", \"X\"\n\n``\"custom\"`` always uses the constraints. Whether it uses forecasts\nand actuals depends on the optimization terms:\n\n- ``forecasts``: used for adjustment penalty, train penalty, variance penalty\n  with \"sample\" covariance, preset weight options (\"MedAPE\", \"InverseMedAPE\").\n- ``actuals``: used for bias penalty, train penalty, variance penalty\n  with \"sample\" covariance, preset weight options (\"MedAPE\", \"InverseMedAPE\").\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train\nWe'll fit to the first half of the data and evaluate accuracy\non the second half.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_size = forecasts.shape[0]//2\nforecasts_train = forecasts.iloc[:train_size,:]\nactuals_train = actuals.iloc[:train_size,:]\nforecasts_test = forecasts.iloc[train_size:,:]\nactuals_test = actuals.iloc[train_size:,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try the ``\"mint_sample\"`` method.\nFirst, fit the transform and apply it on the training set.\nThe transform matrix is more complex than before.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf = ReconcileAdditiveForecasts()\nraf.fit_transform(  # fits and transforms the training data\n    forecasts=forecasts_train,\n    actuals=actuals_train,\n    levels=levels,\n    method=\"mint_sample\"\n)\nassert raf.transform_matrix is not None    # train fit result, set by fit\nassert raf.adjusted_forecasts is not None  # train transform result, set by transform\nfig = raf.plot_transform_matrix()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, evaluate accuracy on the training set.\nIn our example, all the reconciled forecasts have lower error\nthan the base forecasts on the training set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.evaluate(is_train=True)\nassert raf.evaluation_df is not None         # train evaluation result, set by evaluate\nassert raf.figures is not None               # train evaluation figures, set by evaluate\nassert raf.constraint_violation is not None  # train constraint violation, set by evaluate\nraf.evaluation_df.round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Test\nNext, apply the transform to the test set and evaluate accuracy.\nNot all forecasts have improved on the test set.\nThis demonstrates the importance of test set evaluation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.transform_evaluate(  # transform and evaluates on test data\n    forecasts_test=forecasts_test,\n    actuals_test=actuals_test,\n    ipython_display=False,\n    plot=False,\n)\nassert raf.adjusted_forecasts_test is not None    # test transform result, set by transform\nassert raf.evaluation_df_test is not None         # test evaluation result, set by evaluate\nassert raf.figures_test is not None               # test evaluation figures, set by evaluate\nassert raf.constraint_violation_test is not None  # test constraint violation, set by evaluate\nraf.evaluation_df_test.round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The results for the test set are in the\n  corresponding attributes ending with ``\"_test\"``.\n\n  As a summary, here are some key attributes containing the results:\n\n  .. code-block:: none\n\n    transform_matrix :          transform learned from train set\n    adjusted_forecasts :        adjusted forecasts on train set\n    adjusted_forecasts_test :   adjusted forecasts on test set\n    evaluation_df :             evaluation result on train set\n    evaluation_df_test :        evaluation result on test set\n    constraint_violation :      normalized constraint violations on train set\n    constraint_violation_test : normalized constraint violations on test set\n    figures :                   evaluation plots on train set\n    figures_test :              evaluation plots on test set\n\n  For full attribute details, see\n  `~greykite.algo.reconcile.convex.reconcile_forecasts.ReconcileAdditiveForecasts`.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Tuning\nNow that you understand the basic usage, we'll introduce some tuning parameters.\nIf you have enough holdout data, you can use the out of sample evaluation to tune the model.\n\nFirst, try the presets for the ``method`` parameter:\n``\"bottom_up\"``, ``\"ols\"``, ``\"mint_sample\"``, ``\"custom\"``.\n\nIf you'd like to tune further, use the ``\"custom\"`` method to tune\nthe optimization objective and constraints.\nThe tuning parameters and their default values are shown below.\nSee `~greykite.algo.reconcile.convex.reconcile_forecasts.ReconcileAdditiveForecasts`\nfor details.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf = ReconcileAdditiveForecasts()\n_ = raf.fit_transform_evaluate(  # fits, transforms, and evaluates on training data\n    forecasts=forecasts_train,\n    actuals=actuals_train,\n    fit_kwargs=dict(  # additional parameters passed to fit()\n        levels=levels,\n        method=\"custom\",\n        # tuning parameters, with their default values for the custom method\n        lower_bound=None,     # Lower bound on each entry of ``transform_matrix``.\n        upper_bound=None,     # Upper bound on each entry of ``transform_matrix``.\n        unbiased=True,        # Whether the resulting transformation must be unbiased.\n        lam_adj=1.0,          # Weight for the adjustment penalty (adj forecast - forecast)\n        lam_bias=1.0,         # Weight for the bias penalty (adj actual - actual).\n        lam_train=1.0,        # Weight for the training MSE penalty (adj forecast - actual)\n        lam_var=1.0,          # Weight for the variance penalty (variance of adjusted forecast errors for an unbiased transformation, assuming base forecasts are unbiased)\n        covariance=\"sample\",  # Variance-covariance matrix of base forecast errors, used to compute the variance penalty (\"sample\", \"identity\" or numpy array)\n        weight_adj=None,      # Weight for the adjustment penalty to put a different weight per-timeseries.\n        weight_bias=None,     # Weight for the bias penalty to put a different weight per-timeseries.\n        weight_train=None,    # Weight for the train MSE penalty to put a different weight per-timeseries.\n        weight_var=None,      # Weight for the variance penalty to put a different weight per-timeseries.\n    ),\n    evaluate_kwargs=dict()  # additional parameters passed to evaluate()\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using ``\"custom\"`` with default settings,\nwe find good training set performance overall.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.evaluation_df.round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test set performance is also good, except for node \"24\".\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.transform_evaluate(\n    forecasts_test=forecasts_test,\n    actuals_test=actuals_test,\n    ipython_display=False,\n    plot=False\n)\nraf.evaluation_df_test.round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice from the tables that node \"24\" had the most accurate\nbase forecast of all nodes. Therefore, we don't want its adjusted\nforecast to change much. It's possible that the above\ntransform was overfitting this node.\n\nWe can increase the adjustment penalty for node \"24\"\nso that its adjusted forecast will be closer to the original one.\nThis should allow us to get good forecasts overall and\nfor node \"24\" specifically.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# the order of `weights` corresponds to `forecasts.columns`\nweight = np.array([1, 1, 1, 1, 1, 1, 1, 5])  # weight is 5x higher for node \"24\"\nraf = ReconcileAdditiveForecasts()\n_ = raf.fit_transform_evaluate(\n    forecasts=forecasts_train,\n    actuals=actuals_train,\n    fit_kwargs=dict(\n        levels=levels,\n        method=\"custom\",\n        lower_bound=None,\n        upper_bound=None,\n        unbiased=True,\n        lam_adj=1.0,\n        lam_bias=1.0,\n        lam_train=1.0,\n        lam_var=1.0,\n        covariance=\"sample\",\n        weight_adj=weight,    # apply the weights to adjustment penalty\n        weight_bias=None,\n        weight_train=None,\n        weight_var=None,\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>The default ``weight=None`` puts equal weight on all nodes.\n   Weight can also be ``\"MedAPE\"`` (proportional to MedAPE\n   of base forecasts), ``\"InverseMedAPE\"`` (proportional to 1/MedAPE\n   of base forecasts), or a numpy array that specifies the weight\n   for each node.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>When the transform is unbiased (``unbiased=True``),\n   the bias penalty is zero, so ``lam_bias`` and\n   ``weight_bias`` have no effect.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The training error looks good.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.evaluation_df.round(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plots of the transform matrix and adjustment size\nshow that node \"24\"'s adjusted forecast is almost the\nsame as its base forecast.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = raf.plot_transform_matrix()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotly.io.show(raf.figures[\"adj_size\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The test error looks better than before.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Transform and evaluate on the test set.\nraf.transform_evaluate(\n    forecasts_test=forecasts_test,\n    actuals_test=actuals_test,\n    ipython_display=False,\n    plot=True,\n    plot_num_cols=2,\n)\nraf.evaluation_df_test.round(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotly.io.show(raf.figures_test[\"base_adj\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotly.io.show(raf.figures_test[\"adj_size\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotly.io.show(raf.figures_test[\"error\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuning Tips\n\nIf you have enough data, you can use cross validation with multiple test sets\nfor a better estimate of test error. You can use test error to select the parameters.\n\nTo tune the parameters,\n\n1. Try all four methods.\n2. Tune the lambdas and the weights for the custom method.\n\nFor example, start with these lambda settings to see\nwhich penalties are useful:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "lambdas = [\n    # lam_adj, lam_bias, lam_train, lam_var\n    (0, 0, 0, 1),  # the same as \"mint_sample\" if other params are set to default values.\n    (0, 0, 1, 1),\n    (1, 0, 0, 1),\n    (1, 0, 1, 1),  # the same as \"custom\" if other params are set to default values.\n    (1, 1, 1, 1),  # try this one with unbiased=False\n]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tips:\n\n* ``var`` penalty is usually helpful\n* ``train``, ``adj``, ``bias`` penalties are sometimes helpful\n* You can increase the lambda for penalties that are more helpful.\n\nTo try a biased transform, set ``(unbiased=False, lam_bias>0)``.\nAvoid ``(unbiased=False, lam_bias=0)``, because that can result in high bias.\n\nChoose weights that fit your needs. For example, you may care about\nthe accuracy of some forecasts more than others.\n\nSetting ``weight_adj`` to ``\"InverseMedAPE\"`` is a convenient way to\npenalize adjustment to base forecasts that are already accurate.\n\nSetting ``weight_bias``, ``weight_train``, or ``weight_var``\nto ``\"MedAPE\"`` is a convenient way to improve the error\non base forecasts that start with high error.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Debugging\nSome tips if you need to debug:\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Make sure the constraints are properly encoded\n(for the bottom up method, another way is to check\nthe transform matrix).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.constraint_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. The constraint violation should be 0 for the actuals.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.constraint_violation\nraf.constraint_violation_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Check the transform matrix to understand predictions.\n\n.. code-block::\n\n  fig = raf.plot_transform_matrix()\n  plotly.io.show(fig)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. For all methods besides \"bottom_up\", check if a solution was found to the optimization problem.\nIf False, then the ``transform_matrix`` may be set to a fallback option (bottom up transform, if available).\nA warning is printed when this happens (\"Failed to find a solution. Falling back to bottom-up method.\").\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.is_optimization_solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Check ``prob.status`` for details about cvxpy solver status\nand look for printed warnings for any issues. You can pass solver options\nto the ``fit`` method. See\n`~greykite.algo.reconcile.convex.reconcile_forecasts.ReconcileAdditiveForecasts`\nfor details.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.prob.status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Inspect the objective function value at the identified\nsolution and its breakdown into components. This shows the terms\nin the objective after multiplication by the lambdas/weights.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.objective_fn_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Check objective function weights, to make sure\ncovariance, etc., match expectations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raf.objective_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. Check the convex optimization problem.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(type(raf.prob))\nraf.prob"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}