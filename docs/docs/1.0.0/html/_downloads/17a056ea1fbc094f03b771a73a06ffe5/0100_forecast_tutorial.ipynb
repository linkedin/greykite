{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Tune your first forecast model\n\nThis is a basic tutorial for creating and tuning a forecast model.\nIt is intended to provide a basic sense of a forecast process without\nassuming background knowledge in forecasting.\n\nYou can use the ``PROPHET`` or ``SILVERKITE`` model.\nIn this tutorial, we focus on ``SILVERKITE``.\nHowever, the basic ideas of tuning are similar to both models.\nYou may see detailed information about ``PROPHET`` at\n`Prophet <../../pages/model_components/0100_introduction.html#prophet>`_.\n\n\n``SILVERKITE`` decomposes time series into various components, and it\ncreates time-based features, autoregressive features,\ntogether with user-provided features such as macro-economic features\nand their interactions, then performs a machine learning regression\nmodel to learn the relationship between the time series and these\nfeatures. The forecast is based on the learned relationship and\nthe future values of these features. Therefore, including the correct\nfeatures is the key to success.\n\nCommon features include:\n\n    Datetime derivatives:\n        Including features derived from datetime such as ``day of year``,\n        ``hour of day``, ``weekday``, ``is_weekend`` and etc.\n        These features are useful in capturing special patterns.\n        For example, the patterns of weekdays and weekends are different\n        for most business related time series, and this can be modeled with ``is_weekend``.\n    Growth:\n        First defines the basic feature ``ct1`` that counts how\n        long has passed in terms of years (could be fraction)\n        since the first day of training data.\n        For example, if the training data starts with \"2018-01-01\",\n        then the date has ``ct1=0.0``, and \"2018-01-02\" has ``ct1=1/365``.\n        \"2019-01-01\" has ``ct1=1.0``. This ``ct1`` can be as granular\n        as needed. A separate growth function can be applied to ``ct1``\n        to support different types of growth model. For example, ``ct2``\n        is defined as the square of ``ct1`` to model quadratic growth.\n    Trend:\n        Trend describes the average tendency of the time series.\n        It is defined through the growth term with possible changepoints.\n        At every changepoint, the growth rate could change (faster or slower).\n        For example, if ``ct1`` (linear growth) is used with changepoints,\n        the trend is modeled as piece-wise linear.\n    Seasonality:\n        Seasonality describes the periodical pattern of the time series.\n        It contains multiple levels including daily seasonality, weekly seasonality,\n        monthly seasonality, quarterly seasonality and yearly seasonality.\n        Seasonality are defined through Fourier series with different orders.\n        The greater the order, the more detailed periodical pattern the model\n        can learn. However, an order that is too large can lead to overfitting.\n    Events:\n        Events include holidays and other short-term occurrences that could\n        temporarily affect the time series, such as Thanksgiving long weekend.\n        Typically, events are regular and repeat at know times in the future.\n        These features made of indicators that covers the event day and their neighbor days.\n    Autoregression:\n        Autoregressive features include the time series observations\n        in the past and their aggregations. For example, the past day's observation,\n        the same weekday on the past week, or the average of the past 7 days, etc.\n        can be used. Note that autoregression features are very useful in short term\n        forecasts, however, this should be avoided in long term forecast.\n        The reason is that long-term forecast focuses more on the correctness\n        of trend, seasonality and events. The lags and autoregressive terms in\n        a long-term forecast are calculated based on the forecasted values.\n        The further we forecast into the future, the more forecasted values we\n        need to create the autoregressive terms, making the forecast less stable.\n    Custom:\n        Extra features that are relevant to the time series such as macro-ecomonic\n        features that are expected to affect the time series.\n        Note that these features need to be manually provided for both\n        the training and forecasting periods.\n    Interactions:\n        Any interaction between the features above.\n\nNow let's use an example to go through the full forecasting and tuning process.\nIn this example, we'll load a dataset representing ``log(daily page views)``\non the Wikipedia page for Peyton Manning.\nIt contains values from 2007-12-10 to 2016-01-20. More dataset info\n`here <https://facebook.github.io/prophet/docs/quick_start.html>`_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import datetime\n\nimport numpy as np\nimport pandas as pd\nimport plotly\n\nfrom greykite.algo.changepoint.adalasso.changepoint_detector import ChangepointDetector\nfrom greykite.algo.forecast.silverkite.constants.silverkite_holiday import SilverkiteHoliday\nfrom greykite.algo.forecast.silverkite.constants.silverkite_seasonality import SilverkiteSeasonalityEnum\nfrom greykite.algo.forecast.silverkite.forecast_simple_silverkite_helper import cols_interact\nfrom greykite.common import constants as cst\nfrom greykite.common.features.timeseries_features import build_time_features_df\nfrom greykite.common.features.timeseries_features import convert_date_to_continuous_time\nfrom greykite.framework.benchmark.data_loader_ts import DataLoaderTS\nfrom greykite.framework.templates.autogen.forecast_config import EvaluationPeriodParam\nfrom greykite.framework.templates.autogen.forecast_config import ForecastConfig\nfrom greykite.framework.templates.autogen.forecast_config import MetadataParam\nfrom greykite.framework.templates.autogen.forecast_config import ModelComponentsParam\nfrom greykite.framework.templates.forecaster import Forecaster\nfrom greykite.framework.templates.model_templates import ModelTemplateEnum\nfrom greykite.framework.utils.result_summary import summarize_grid_search_results\n\n\n# Loads dataset into UnivariateTimeSeries\ndl = DataLoaderTS()\nts = dl.load_peyton_manning_ts()\ndf = ts.df  # cleaned pandas.DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory data analysis (EDA)\nAfter reading in a time series, we could first do some exploratory data analysis.\nThe `~greykite.framework.input.univariate_time_series.UnivariateTimeSeries` class is\nused to store a timeseries and perform EDA.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# describe\nprint(ts.describe_time_col())\nprint(ts.describe_value_col())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The df has two columns, time column \"ts\" and value column \"y\".\nThe data is daily that ranges from 2007-12-10 to 2016-01-20.\nThe data value ranges from 5.26 to 12.84\n\nLet's plot the original timeseries.\n(The interactive plot is generated by ``plotly``: **click to zoom!**)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ts.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A few exploratory plots can be plotted to reveal the time series's properties.\nThe `~greykite.framework.input.univariate_time_series.UnivariateTimeSeries` class\nhas a very powerful plotting tool\n`~greykite.framework.input.univariate_time_series.UnivariateTimeSeries.plot_quantiles_and_overlays`.\nA tutorial of using the function can be found at :doc:`/gallery/quickstart/01_exploration/0300_seasonality_plots`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline model\nA simple forecast can be created on the data set,\nsee details in :doc:`/gallery/quickstart/0100_simple_forecast`.\nNote that if you do not provide any extra parameters, all model parameters are by default.\nThe default parameters are chosen conservatively, so consider this a baseline\nmodel to assess forecast difficulty and make further improvements if necessary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Specifies dataset information\nmetadata = MetadataParam(\n    time_col=\"ts\",  # name of the time column\n    value_col=\"y\",  # name of the value column\n    freq=\"D\"  # \"H\" for hourly, \"D\" for daily, \"W\" for weekly, etc.\n)\n\nforecaster = Forecaster()\nresult = forecaster.run_forecast_config(\n    df=df,\n    config=ForecastConfig(\n        model_template=ModelTemplateEnum.SILVERKITE.name,\n        forecast_horizon=365,  # forecasts 365 steps ahead\n        coverage=0.95,  # 95% prediction intervals\n        metadata_param=metadata\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For a detailed documentation about the output from\n:py:meth:`~greykite.framework.templates.forecaster.Forecaster.run_forecast_config`,\nsee :doc:`/pages/stepbystep/0500_output`. Here we could plot the forecast.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "forecast = result.forecast\nfig = forecast.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model performance evaluation\nWe can see the forecast fits the existing data well; however, we do not\nhave a good ground truth to assess how well it predicts into the future.\n\n### Train-test-split\nThe typical way to evaluate model performance is to reserve part of the training\ndata and use it to measure the model performance.\nBecause we always predict the future in a time series forecasting problem,\nwe reserve data from the end of training set to measure the performance\nof our forecasts. This is called a time series train test split.\n\nBy default, the results returned by :py:meth:`~greykite.framework.templates.forecaster.Forecaster.run_forecast_config`\ncreates a time series train test split and stores the test result in ``result.backtest``.\nThe reserved testing data by default has the\nsame length as the forecast horizon. We can access the evaluation results:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(result.backtest.test_evaluation, index=[\"Value\"]).transpose()  # formats dictionary as a pd.DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation metrics\nFrom here we can see a list of metrics that measure the model performance on the test data.\nYou may choose one or a few metrics to focus on. Typical metrics include:\n\n  MSE:\n      Mean squared error, the average squared error. Could be affected by extreme values.\n\n  RMSE:\n      Root mean squared error, the square root of MSE.\n\n  MAE:\n      Mean absolute error, the average of absolute error. Could be affected by extreme values.\n\n  MedAE:\n      Median absolute error, the median of absolute error. Less affected by extreme values.\n\n  MAPE:\n      Mean absolute percent error, measures the error percent with respective to the true values.\n      This is useful when you would like to consider the relative error instead of the absolute error.\n      For example, an error of 1 is considered as 10% for a true observation of 10, but as 1% for a true\n      observation of 100. This is the default metric we like.\n\n  MedAPE:\n      Median absolute percent error, the median version of MAPE, less affected by extreme values.\n\nLet's use MAPE as our metric in this example. Looking at these results,\nyou may have a basic sense of how the model is performing on the unseen test data.\nOn average, the baseline model's prediction is 11.3% away from the true values.\n\n### Time series cross-validation\nForecast quality depends a lot of the evaluation time window.\nThe evaluation window selected above might happen to be a relatively easy/hard period to predict.\nThus, it is more robust to evaluate over a longer time window when dataset size allows.\nLet's consider a more general way of evaluating a forecast model: time series cross-validation.\n\nTime series cross-validation is based on a time series rolling split.\nLet's say we would like to perform an evaluation with a 3-fold cross-validation,\nThe whole training data is split in 3 different ways.\nSince our forecast horizon is 365 days, we do:\n\n    First fold:\n      Train from 2007-12-10 to 2013-01-20, forecast from\n      2013-01-21 to 2014-01-20, and compare the forecast with the actual.\n    Second fold:\n      Train from 2007-12-10 to 2014-01-20, forecast from\n      2014-01-21 to 2015-01-20, and compare the forecast with the actual.\n    Third fold:\n      Train from 2007-12-10 to 2015-01-20, forecast from\n      2015-01-21 to 2016-01-20, and compare the forecast with the actual.\n\nThe split could be more flexible, for example, the testing periods could have gaps.\nFor more details about evaluation period configuration, see\n`Evaluation Period <../../pages/stepbystep/0400_configuration.html#evaluation-period>`_.\nThe forecast model's performance will be the average of the three evaluations\non the forecasts.\n\nBy default, the results returned by :py:meth:`~greykite.framework.templates.forecaster.Forecaster.run_forecast_config`\nalso runs time series cross-validation internally.\nYou are allowed to configure the cross-validation splits, as shown below.\nHere note that the ``test_horizon`` are reserved from the back of\nthe data and not used for cross-validation.\nThis part of testing data can further evaluate the model performance\nbesides the cross-validation result, and is available for plotting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Defines the cross-validation config\nevaluation_period = EvaluationPeriodParam(\n    test_horizon=365,             # leaves 365 days as testing data\n    cv_horizon=365,               # each cv test size is 365 days (same as forecast horizon)\n    cv_max_splits=3,              # 3 folds cv\n    cv_min_train_periods=365 * 4  # uses at least 4 years for training because we have 8 years data\n)\n\n# Runs the forecast\nresult = forecaster.run_forecast_config(\n    df=df,\n    config=ForecastConfig(\n        model_template=ModelTemplateEnum.SILVERKITE.name,\n        forecast_horizon=365,  # forecasts 365 steps ahead\n        coverage=0.95,  # 95% prediction intervals\n        metadata_param=metadata,\n        evaluation_period_param=evaluation_period\n    )\n)\n\n# Summarizes the cv result\ncv_results = summarize_grid_search_results(\n    grid_search=result.grid_search,\n    decimals=1,\n    # The below saves space in the printed output. Remove to show all available metrics and columns.\n    cv_report_metrics=None,\n    column_order=[\"rank\", \"mean_test\", \"split_test\", \"mean_train\", \"split_train\", \"mean_fit_time\", \"mean_score_time\", \"params\"])\n# Transposes to save space in the printed output\ncv_results[\"params\"] = cv_results[\"params\"].astype(str)\ncv_results.set_index(\"params\", drop=True, inplace=True)\ncv_results.transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By default, all metrics in `~greykite.common.evaluation.ElementwiseEvaluationMetricEnum`\nare computed on each CV train/test split.\nThe configuration of CV evaluation metrics can be found at\n`Evaluation Metric <../../pages/stepbystep/0400_configuration.html#evaluation-metric>`_.\nHere, we show the Mean Absolute Percentage Error (MAPE)\nacross splits (see `~greykite.framework.utils.result_summary.summarize_grid_search_results`\nto control what to show and for details on the output columns).\nFrom the result, we see that the cross-validation ``mean_test_MAPE`` is 7.3%, which\nmeans the prediction is 7.3% away from the ground truth on average. We also see the\n3 cv folds have ``split_test_MAPE`` 5.1%, 8.5% and 8.4%, respectively.\n\nWhen we have different sets of model parameters, a good way to compare them is\nto run a time series cross-validation on each set of parameters, and pick the\nset of parameters that has the best cross-validated performance.\n\n## Start tuning\nNow that you know how to evaluate model performance,\nlet's see if we can improve the model by tuning its parameters.\n\n### Anomaly\nAn anomaly is a deviation in the metric that is not expected to occur again\nin the future. Including anomaly points will lead the model to fit the\nanomaly as an intrinsic property of the time series, resulting in inaccurate forecasts.\nThese anomalies could be identified through overlay plots, see\n:doc:`/gallery/quickstart/01_exploration/0300_seasonality_plots`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ts.plot_quantiles_and_overlays(\n    groupby_time_feature=\"month_dom\",\n    show_mean=True,\n    show_quantiles=False,\n    show_overlays=True,\n    overlay_label_time_feature=\"year\",\n    overlay_style={\"line\": {\"width\": 1}, \"opacity\": 0.5},\n    center_values=True,\n    xlabel=\"day of year\",\n    ylabel=ts.original_value_col,\n    title=\"yearly seasonality for each year (centered)\",\n)\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the yearly overlay plot above, we could see two big anomalies:\none in March of 2012, and one in June of 2010. Other small anomalies\ncould be identified as well, however, they have less influence.\nThe ``SILVERKITE`` template currently supports masking anomaly points\nby supplying the ``anomaly_info`` as a dictionary. You could\neither assign adjusted values to them, or simply mask them as NA\n(in which case these dates will not be used in fitting).\nFor a detailed introduction about the ``anomaly_info`` configuration,\nsee :doc:`/pages/stepbystep/0300_input`.\nHere we define an ``anomaly_df`` dataframe to mask them as NA,\nand wrap it into the ``anomaly_info`` dictionary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "anomaly_df = pd.DataFrame({\n    # start and end date are inclusive\n    # each row is an anomaly interval\n    cst.START_TIME_COL: [\"2010-06-05\", \"2012-03-01\"],  # inclusive\n    cst.END_TIME_COL: [\"2010-06-20\", \"2012-03-20\"],  # inclusive\n    cst.ADJUSTMENT_DELTA_COL: [np.nan, np.nan],  # mask as NA\n})\n# Creates anomaly_info dictionary.\n# This will be fed into the template.\nanomaly_info = {\n    \"value_col\": \"y\",\n    \"anomaly_df\": anomaly_df,\n    \"adjustment_delta_col\": cst.ADJUSTMENT_DELTA_COL,\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding relevant features\n\n#### Growth and trend\nFirst we look at the growth and trend. Detailed growth configuration can be found\nat :doc:`/pages/model_components/0200_growth`.\nIn these two features, we care less about the short-term fluctuations but rather long-term tendency.\nFrom the original plot we see there is no obvious growth pattern, thus we\ncould use a linear growth to fit the model. On the other hand, there could be\npotential trend changepoints, at which time the linear growth changes its rate.\nDetailed changepoint configuration can be found at :doc:`/pages/model_components/0500_changepoints`.\nThese points can be detected with the ``ChangepointDetector`` class. For a quickstart example,\nsee :doc:`/gallery/quickstart/01_exploration/0100_changepoint_detection`.\nHere we explore the automatic changepoint detection.\nThe parameters in this automatic changepoint detection is customized for this data set.\nWe keep the ``yearly_seasonality_order`` the same as the model's yearly seasonality order.\nThe ``regularization_strength`` controls how many changepoints are detected.\n0.5 is a good choice, while you may try other numbers such as 0.4 or 0.6 to see the difference.\nThe ``resample_freq`` is set to 7 days, because we have a long training history, thus we should\nkeep this relatively long (the intuition is that shorter changes will be ignored).\nWe put 25 potential changepoints to be the candidates, because we do not expect too many changes.\nHowever, this could be higher.\nThe ``yearly_seasonality_change_freq`` is set to 365 days, which means we refit the yearly seasonality\nevery year, because it can be see from the time series plot that the yearly seasonality varies every year.\nThe ``no_changepoint_distance_from_end`` is set to 365 days, which means we do not allow any changepoints\nat the last 365 days of training data. This avoids fitting the final trend with too little data.\nFor long-term forecast, this is typically the same as the forecast horizon, while for short-term forecast,\nthis could be a multiple of the forecast horizon.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = ChangepointDetector()\nres = model.find_trend_changepoints(\n    df=df,  # data df\n    time_col=\"ts\",  # time column name\n    value_col=\"y\",  # value column name\n    yearly_seasonality_order=10,  # yearly seasonality order, fit along with trend\n    regularization_strength=0.5,  # between 0.0 and 1.0, greater values imply fewer changepoints, and 1.0 implies no changepoints\n    resample_freq=\"7D\",  # data aggregation frequency, eliminate small fluctuation/seasonality\n    potential_changepoint_n=25,  # the number of potential changepoints\n    yearly_seasonality_change_freq=\"365D\",  # varying yearly seasonality for every year\n    no_changepoint_distance_from_end=\"365D\")  # the proportion of data from end where changepoints are not allowed\nfig = model.plot(\n    observation=True,\n    trend_estimate=False,\n    trend_change=True,\n    yearly_seasonality_estimate=False,\n    adaptive_lasso_estimate=True,\n    plot=False)\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the plot we see the automatically detected trend changepoints.\nThe results shows that the time series is generally increasing until 2012,\nthen generally decreasing. One possible explanation is that 2011 is\nthe last year Peyton Manning was at the Indianapolis Colts before joining the\nDenver Broncos. If we feed the trend changepoint detection parameter to the template,\nthese trend changepoint features will be automatically included in the model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The following specifies the growth and trend changepoint configurations.\ngrowth = {\n    \"growth_term\": \"linear\"\n}\nchangepoints = {\n    \"changepoints_dict\": dict(\n        method=\"auto\",\n        yearly_seasonality_order=10,\n        regularization_strength=0.5,\n        resample_freq=\"7D\",\n        potential_changepoint_n=25,\n        yearly_seasonality_change_freq=\"365D\",\n        no_changepoint_distance_from_end=\"365D\"\n    )\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Seasonality\nThe next features we will look into are the seasonality features.\nDetailed seasonality configurations can be found at\n:doc:`/pages/model_components/0300_seasonality`.\nA detailed seasonality detection quickstart example on the same data set is\navailable at :doc:`/gallery/quickstart/01_exploration/0300_seasonality_plots`.\nThe conclusions about seasonality terms are:\n\n  - daily seasonality is not available (because frequency is daily);\n  - weekly and yearly patterns are evident (weekly will also interact with football season);\n  - monthly or quarterly seasonality is not evident.\n\nTherefore, for pure seasonality terms, we include weekly and yearly\nseasonality. The seasonality orders are something to be tuned; here\nlet's take weekly seasonality order to be 5 and yearly seasonality order to be 10.\nFor tuning info, see :doc:`/pages/model_components/0300_seasonality`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Includes yearly seasonality with order 10 and weekly seasonality with order 5.\n# Set the other seasonality to False to disable them.\nyearly_seasonality_order = 10\nweekly_seasonality_order = 5\nseasonality = {\n    \"yearly_seasonality\": yearly_seasonality_order,\n    \"quarterly_seasonality\": False,\n    \"monthly_seasonality\": False,\n    \"weekly_seasonality\": weekly_seasonality_order,\n    \"daily_seasonality\": False\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will add the interaction between weekly seasonality and the football season\nlater in this tutorial.\nThe ``SILVERKITE`` template also supports seasonality changepoints. A seasonality\nchangepoint is a time point after which the periodic effect behaves\ndifferently. For ``SILVERKITE``, this means the Fourier series coefficients are allowed\nto change. We could decide to add this feature if cross-validation performance is poor\nand seasonality changepoints are detected in exploratory analysis.\nFor details, see :doc:`/gallery/quickstart/01_exploration/0100_changepoint_detection`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Holidays and events\nThen let's look at holidays and events. Detailed holiday and event configurations\ncan be found at :doc:`/pages/model_components/0400_events`.\nAsk yourself which holidays are likely to affect the time series' values.\nWe expect that major United States holidays may affect wikipedia pageviews,\nsince most football fans are in the United States.\nEvents such as superbowl could potentially increase the pageviews.\nTherefore, we add United States holidays and superbowls dates as custom events.\nOther important events that affect the time series can also be found\nthrough the yearly seasonality plots in :doc:`/gallery/quickstart/01_exploration/0300_seasonality_plots`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Includes major holidays and the superbowl date.\nevents = {\n    # These holidays as well as their pre/post dates are modeled as individual events.\n    \"holidays_to_model_separately\": SilverkiteHoliday.ALL_HOLIDAYS_IN_COUNTRIES,  # all holidays in \"holiday_lookup_countries\"\n    \"holiday_lookup_countries\": [\"UnitedStates\"],  # only look up holidays in the United States\n    \"holiday_pre_num_days\": 2,  # also mark the 2 days before a holiday as holiday\n    \"holiday_post_num_days\": 2,  # also mark the 2 days after a holiday as holiday\n    \"daily_event_df_dict\": {\n        \"superbowl\": pd.DataFrame({\n            \"date\": [\"2008-02-03\", \"2009-02-01\", \"2010-02-07\", \"2011-02-06\",\n                     \"2012-02-05\", \"2013-02-03\", \"2014-02-02\", \"2015-02-01\", \"2016-02-07\"],  # dates must cover training and forecast period.\n            \"event_name\": [\"event\"] * 9  # labels\n        })\n    },\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Autoregression\nThe autoregressive features are very useful in short-term forecasting, but\ncould be risky to use in long-term forecasting. Detailed autoregression\nconfigurations can be found at :doc:`/pages/model_components/0800_autoregression`.\n\n#### Custom\nNow we consider some custom features that could relate to the pageviews. The documentation for\nextra regressors can be found at :Doc:`/pages/model_components/0700_regressors`. As mentioned\nin :doc:`/gallery/quickstart/01_exploration/0300_seasonality_plots`, we observe that the football\nseason heavily affects the pageviews, therefore we need to use regressors to identify the football season.\nThere are multiple ways to include this feature: adding indicator for the whole season;\nadding number of days till season start (end) and number of days since season start (end).\nThe former puts a uniform effect over all in-season dates, while the latter quantify\nthe on-ramp and down-ramp. If you are not sure which effect to include, it's ok to include both\neffects. ``SILVERKITE`` has the option to use Ridge regression as the fit algorithm to avoid\nover-fitting too many features. Note that many datetime features could also be added to\nthe model as features. ``SILVERKITE`` calculates some of these features, which can be added to\n``extra_pred_cols`` as an arbitrary patsy expression.\nFor a full list of such features, see `~greykite.common.features.timeseries_features.build_time_features_df`.\n\nIf a feature is not automatically created by ``SILVERKITE``, we need to create it\nbeforehand and append it to the data df.\nHere we create the \"is_football_season\" feature.\nNote that we also need to provide the customized column for the forecast horizon period as well.\nThe way we do it is to first create the df with timestamps covering the forecast horizon.\nThis can be done with the `~greykite.framework.input.univariate_time_series.UnivariateTimeSeries.make_future_dataframe`\nfunction within the `~greykite.framework.input.univariate_time_series.UnivariateTimeSeries` class.\nThen we create a new column of our customized regressor for this augmented df.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Makes augmented df with forecast horizon 365 days\ndf_full = ts.make_future_dataframe(periods=365)\n# Builds \"df_features\" that contains datetime information of the \"df\"\ndf_features = build_time_features_df(\n    dt=df_full[\"ts\"],\n    conti_year_origin=convert_date_to_continuous_time(df_full[\"ts\"][0])\n)\n\n# Roughly approximates the football season.\n# \"woy\" is short for \"week of year\", created above.\n# Football season is roughly the first 6 weeks and last 17 weeks in a year.\nis_football_season = (df_features[\"woy\"] <= 6) | (df_features[\"woy\"] >= 36)\n# Adds the new feature to the dataframe.\ndf_full[\"is_football_season\"] = is_football_season.astype(int).tolist()\ndf_full.reset_index(drop=True, inplace=True)\n\n# Configures regressor column.\nregressors = {\n    \"regressor_cols\": [\"is_football_season\"]\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Interactions\nFinally, let's consider what possible interactions are relevant to the forecast problem.\nGenerally speaking, if a feature behaves differently on different values of another feature,\nthese two features could have potential interaction effects.\nAs in :doc:`/gallery/quickstart/01_exploration/0300_seasonality_plots`, the weekly seasonality\nis different through football season and non-football season, therefore, the multiplicative\nterm ``is_football_season x weekly_seasonality`` is able to capture this pattern.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ts.plot_quantiles_and_overlays(\n    groupby_time_feature=\"str_dow\",\n    show_mean=True,\n    show_quantiles=False,\n    show_overlays=True,\n    center_values=True,\n    overlay_label_time_feature=\"month\",  # splits overlays by month\n    overlay_style={\"line\": {\"width\": 1}, \"opacity\": 0.5},\n    xlabel=\"day of week\",\n    ylabel=ts.original_value_col,\n    title=\"weekly seasonality by month\",\n)\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's create the interaction terms: interaction between ``is_football_season`` and ``weekly seasonality``.\nThe interaction terms between a feature and a seasonality feature\ncan be created with the `~greykite.algo.forecast.silverkite.forecast_simple_silverkite_helper.cols_interact` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "football_week = cols_interact(\n    static_col=\"is_football_season\",\n    fs_name=SilverkiteSeasonalityEnum.WEEKLY_SEASONALITY.value.name,\n    fs_order=weekly_seasonality_order,\n    fs_seas_name=SilverkiteSeasonalityEnum.WEEKLY_SEASONALITY.value.seas_names\n)\n\nextra_pred_cols = football_week"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Moreover, the multiplicative term ``month x weekly_seasonality`` and the ``dow_woy`` features also\naccount for the varying weekly seasonality through the year. One could added these features, too.\nHere we just leave them out. You may use ``cols_interact`` again to create the ``month x weekly_seasonality``\nsimilar to ``is_football_season x weekly_seasonality``. ``dow_woy`` is automatically calcuated by ``SILVERKITE``,\nyou may simply append the name to ``extra_pred_cols`` to include it in the model.\n\n### Putting things together\nNow let's put everything together and produce a new forecast.\nA detailed template documentation can be found at\n:doc:`/pages/stepbystep/0400_configuration`.\nWe first configure the ``MetadataParam`` class.\nThe ``MetadataParam`` class includes basic proporties of the time series itself.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metadata = MetadataParam(\n    time_col=\"ts\",              # column name of timestamps in the time series df\n    value_col=\"y\",              # column name of the time series values\n    freq=\"D\",                   # data frequency, here we have daily data\n    anomaly_info=anomaly_info,  # this is the anomaly information we defined above,\n    train_end_date=datetime.datetime(2016, 1, 20)\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we define the ``ModelComponentsParam`` class based on the discussion on relevant features.\nThe ``ModelComponentsParam`` include properties related to the model itself.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_components = ModelComponentsParam(\n    seasonality=seasonality,\n    growth=growth,\n    events=events,\n    changepoints=changepoints,\n    autoregression=None,\n    regressors=regressors,  # is_football_season defined above\n    uncertainty={\n        \"uncertainty_dict\": \"auto\",\n    },\n    custom={\n        # What algorithm is used to learn the relationship between the time series and the features.\n        # Regularized fitting algorithms are recommended to mitigate high correlations and over-fitting.\n        # If you are not sure what algorithm to use, \"ridge\" is a good choice.\n        \"fit_algorithm_dict\": {\n            \"fit_algorithm\": \"ridge\",\n        },\n        \"extra_pred_cols\": extra_pred_cols  # the interaction between is_football_season and weekly seasonality defined above\n    }\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's run the model with the new configuration.\nThe evaluation config is kept the same as the previous case;\nthis is important for a fair comparison of parameter sets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Runs the forecast\nresult = forecaster.run_forecast_config(\n    df=df_full,\n    config=ForecastConfig(\n        model_template=ModelTemplateEnum.SILVERKITE.name,\n        forecast_horizon=365,  # forecasts 365 steps ahead\n        coverage=0.95,  # 95% prediction intervals\n        metadata_param=metadata,\n        model_components_param=model_components,\n        evaluation_period_param=evaluation_period\n    )\n)\n\n# Summarizes the cv result\ncv_results = summarize_grid_search_results(\n    grid_search=result.grid_search,\n    decimals=1,\n    # The below saves space in the printed output. Remove to show all available metrics and columns.\n    cv_report_metrics=None,\n    column_order=[\"rank\", \"mean_test\", \"split_test\", \"mean_train\", \"split_train\", \"mean_fit_time\", \"mean_score_time\", \"params\"])\n# Transposes to save space in the printed output\ncv_results[\"params\"] = cv_results[\"params\"].astype(str)\ncv_results.set_index(\"params\", drop=True, inplace=True)\ncv_results.transpose()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we see that after analyzing the problem and adding appropriate features,\nthe cross-validation test MAPE is 5.4%, which is improved compared with the baseline (7.3%).\nThe 3 cv folds also have their MAPE reduced to 3.9%, 8.7% and 3.8%, respectively.\nThe first and third fold improved significantly. With some investigation, we can see that\nthe second fold did not improve because there is a trend changepoint right at the the start\nof its test period.\n\nIt would be hard to know this situation until we see it. In the cross-validation step, one\nway to avoid this is to set a different evaluation period. However, leaving this period\nalso makes sense because it could happen again in the future.\nIn the forecast period, we could monitor the forecast and actual, and re-train the model\nto adapt to the most recent pattern if we see a deviation. In the changepoints dictionary,\ntune ``regularization_strength`` or ``no_changepoint_distance_from_end`` accordingly, or\nadd manually specified changepoints to the automatically detected ones. For details, see\n:doc:`/pages/model_components/0500_changepoints`.\n\nWe could also plot the forecast.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "forecast = result.forecast\nfig = forecast.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check model summary\nTo further investigate the model mechanism, it's also helpful\nto see the model summary.\nThe `~greykite.algo.common.model_summary.ModelSummary` module\nprovides model results such as estimations, significance, p-values,\nconfidence intervals, etc.\nthat can help the user understand how the model works and\nwhat can be further improved.\n\nThe model summary is a class method of the estimator and can be used as follows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "summary = result.model[-1].summary()  # -1 retrieves the estimator from the pipeline\nprint(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model summary shows the model information, the coefficients and their significance,\nand a few summary statistics. For example,\nwe can see the changepoints and how much the growth rate\nchanges at each changepoint.\nWe can see that some of the holidays have significant\neffect in the model, such as Christmas, Labor day, Thanksgiving, etc.\nWe can see the significance of the interaction between football season and weekly seasonality\netc.\n\nFor a more detailed guide on model summary, see\n:doc:`/gallery/quickstart/02_interpretability/0100_model_summary`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary in model tuning\nAfter the example, you may have some sense about how to select parameters and tune the model.\nHere we list a few steps and tricks that might help select the best models.\nWhat you may do:\n\n  #. Detect anomaly points with the overlay plots\n     (`~greykite.framework.input.univariate_time_series.UnivariateTimeSeries.plot_quantiles_and_overlays`).\n     Mask these points with NA. Do not specify the adjustment unless you are confident about how to correct the anomalies.\n\n  #. Choose an appropriate way to model the growth (linear, quadratic, square root, etc.)\n     If none of the typical growth shape fits the time series, you might consider linear\n     growth with trend changepoints. Try different changepoint detection configurations.\n     You may also plot the detected changepoints and see if it makes sense to you.\n     The template also supports custom changepoints. If the automatic changepoint detection result\n     does not make sense to you, you might supply your own changepoints.\n\n  #. Choose the appropriate seasonality orders. The higher the order, the more details the model can learn.\n     However, too large orders could overfit the training data. These can also be detected from the\n     overlay plots (`~greykite.framework.input.univariate_time_series.UnivariateTimeSeries.plot_quantiles_and_overlays`).\n     There isn't a unified way to choose seasonality, so explore different seasonality orders and compare the results.\n\n  #. Consider what events and holidays to model. Are there any custom events we need to add?\n     If you add a custom event, remember also adding the dates for the event in the forecast period.\n\n  #. Add external regressors that could be related to the time series. Note that you will need to provide the\n     values of the regressors in the forecast period as well. You may use another time series as a regressor,\n     as long as you have a ground truth/good forecast for it that covers your forecast period.\n\n  #. Adding interaction terms. Let's mention again here that there could be interaction between two features\n     if the behaviors of one feature are different when the other feature have different values.\n     Try to detect this through the overlay plot\n     (`~greykite.framework.input.univariate_time_series.UnivariateTimeSeries.plot_quantiles_and_overlays`), too.\n     By default, we have a few pre-defined interaction terms, see\n     `feature_sets_enabled <../../pages/model_components/0600_custom.html#interactions>`_.\n\n  #. Choose an appropriate fit algorithm. This is the algorithm that models the relationship between the features\n     and the time series. See a full list of available algorithms at\n     `fit_algorithm <../../pages/model_components/0600_custom.html#fit-algorithm>`_.\n     If you are unsure about their difference, try some of them and compare the results. If you don't want to, choosing \"ridge\"\n     is a safe option.\n\nIt is worth noting that the template supports automatic grid search with different sets of parameters.\nFor each parameter, if you provide the configuration in a list, it will automatically run each combination\nand choose the one with the best cross-validation performance. This will save a lot of time.\nFor details, see :doc:`/gallery/quickstart/03_benchmark/0100_grid_search`.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Follow your insights and intuitions, and play with the parameters, you will get good forecasts!\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}