{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Example for monthly data\n\nThis is a basic example for monthly data using Silverkite.\nNote that here we are fitting a few simple models and the goal is not to optimize\nthe results as much as possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\nfrom collections import defaultdict\n\nimport plotly\nimport pandas as pd\n\nfrom greykite.framework.benchmark.data_loader_ts import DataLoaderTS\nfrom greykite.framework.templates.autogen.forecast_config import EvaluationPeriodParam\nfrom greykite.framework.templates.autogen.forecast_config import ForecastConfig\nfrom greykite.framework.templates.autogen.forecast_config import MetadataParam\nfrom greykite.framework.templates.autogen.forecast_config import ModelComponentsParam\nfrom greykite.framework.templates.forecaster import Forecaster\nfrom greykite.framework.templates.model_templates import ModelTemplateEnum\nfrom greykite.framework.utils.result_summary import summarize_grid_search_results\nfrom greykite.framework.input.univariate_time_series import UnivariateTimeSeries\n\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loads dataset into ``UnivariateTimeSeries``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dl = DataLoaderTS()\nagg_func = {\"count\": \"sum\"}\ndf = dl.load_bikesharing(agg_freq=\"monthly\", agg_func=agg_func)\n# In this monthly data the last month data is incomplete, therefore we drop it\ndf.drop(df.tail(1).index,inplace=True)\ndf.reset_index(drop=True)\nts = UnivariateTimeSeries()\nts.load_data(\n    df=df,\n    time_col=\"ts\",\n    value_col=\"count\",\n    freq=\"MS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory data analysis (EDA)\nAfter reading in a time series, we could first do some exploratory data analysis.\nThe `~greykite.framework.input.univariate_time_series.UnivariateTimeSeries` class is\nused to store a timeseries and perform EDA.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A quick description of the data can be obtained as follows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(ts.describe_time_col())\nprint(ts.describe_value_col())\nprint(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's plot the original timeseries.\n(The interactive plot is generated by ``plotly``: **click to zoom!**)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ts.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Exploratory plots can be plotted to reveal the time series's properties.\nMonthly overlay plot can be used to inspect the annual patterns.\nThis plot overlays various years on top of each other.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = ts.plot_quantiles_and_overlays(\n     groupby_time_feature=\"month\",\n     show_mean=False,\n     show_quantiles=False,\n     show_overlays=True,\n     overlay_label_time_feature=\"year\",\n     overlay_style={\"line\": {\"width\": 1}, \"opacity\": 0.5},\n     center_values=False,\n     xlabel=\"month of year\",\n     ylabel=ts.original_value_col,\n     title=\"yearly seasonality for each year (centered)\",)\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify common metadata.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "forecast_horizon = 4\ntime_col = \"ts\"\nvalue_col = \"count\"\nmeta_data_params = MetadataParam(\n    time_col=time_col,\n    value_col=value_col,\n    freq=\"MS\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify common evaluation parameters.\nSet minimum input data for training.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cv_min_train_periods = 24\n# Let CV use most recent splits for cross-validation.\ncv_use_most_recent_splits = True\n# Determine the maximum number of validations.\ncv_max_splits = 5\nevaluation_period_param = EvaluationPeriodParam(\n    test_horizon=forecast_horizon,\n    cv_horizon=forecast_horizon,\n    periods_between_train_test=0,\n    cv_min_train_periods=cv_min_train_periods,\n    cv_expanding_window=True,\n    cv_use_most_recent_splits=cv_use_most_recent_splits,\n    cv_periods_between_splits=None,\n    cv_periods_between_train_test=0,\n    cv_max_splits=cv_max_splits,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit a simple model without autoregression.\nThe important modeling parameters for monthly data are as follows.\nThese are plugged into ``ModelComponentsParam``.\nThe ``extra_pred_cols`` is used to specify growth and annual seasonality\nGrowth is modelled with both \"ct_sqrt\", \"ct1\" for extra flexibility as we have\nlongterm data and ridge regularization will avoid over-fitting the trend.\nThe annual seasonality is modelled categorically with \"C(month)\" instead of\nFourier series. This is because in monthly data, the number of data points in\nyear is rather small (12) as opposed to daily data where there are many points in\nthe year, which makes categorical representation non-feasible.\nThe categorical representation of monthly also is more explainable/interpretable in the model\nsummary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "extra_pred_cols = [\"ct_sqrt\", \"ct1\", \"C(month, levels=list(range(1, 13)))\"]\nautoregression = None\n\n# Specify the model parameters\nmodel_components = ModelComponentsParam(\n    growth=dict(growth_term=None),\n    seasonality=dict(\n        yearly_seasonality=[False],\n        quarterly_seasonality=[False],\n        monthly_seasonality=[False],\n        weekly_seasonality=[False],\n        daily_seasonality=[False]\n    ),\n    custom=dict(\n        fit_algorithm_dict=dict(fit_algorithm=\"ridge\"),\n        extra_pred_cols=extra_pred_cols\n    ),\n    regressors=dict(regressor_cols=None),\n    autoregression=autoregression,\n    uncertainty=dict(uncertainty_dict=None),\n    events=dict(holiday_lookup_countries=None),\n)\n\n# Run the forecast model\nforecaster = Forecaster()\nresult = forecaster.run_forecast_config(\n    df=df,\n    config=ForecastConfig(\n        model_template=ModelTemplateEnum.SILVERKITE.name,\n        coverage=0.95,\n        forecast_horizon=forecast_horizon,\n        metadata_param=meta_data_params,\n        evaluation_period_param=evaluation_period_param,\n        model_components_param=model_components\n    )\n)\n\n# Get the useful fields from the forecast result\nmodel = result.model[-1]\nbacktest = result.backtest\nforecast = result.forecast\ngrid_search = result.grid_search\n\n# Check model coefficients / variables\n# Get model summary with p-values\nprint(model.summary())\n\n# Get cross-validation results\ncv_results = summarize_grid_search_results(\n    grid_search=grid_search,\n    decimals=2,\n    cv_report_metrics=None,\n    column_order=[\n        \"rank\", \"mean_test\", \"split_test\", \"mean_train\", \"split_train\",\n        \"mean_fit_time\", \"mean_score_time\", \"params\"])\n# Transposes to save space in the printed output\nprint(cv_results.transpose())\n\n# Check historical evaluation metrics (on the historical training/test set).\nbacktest_eval = defaultdict(list)\nfor metric, value in backtest.train_evaluation.items():\n    backtest_eval[metric].append(value)\n    backtest_eval[metric].append(backtest.test_evaluation[metric])\nmetrics = pd.DataFrame(backtest_eval, index=[\"train\", \"test\"]).T\nprint(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit/backtest plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = backtest.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forecast plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = forecast.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The components plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = forecast.plot_components()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit a simple model with autoregression.\nThis is done by specifying the ``autoregression`` parameter in ``ModelComponentsParam``.\nNote that the auto-regressive structure can be customized further depending on your data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "extra_pred_cols = [\"ct_sqrt\", \"ct1\", \"C(month, levels=list(range(1, 13)))\"]\nautoregression = {\n    \"autoreg_dict\": {\n        \"lag_dict\": {\"orders\": [1]},\n        \"agg_lag_dict\": None\n    }\n}\n\n# Specify the model parameters\nmodel_components = ModelComponentsParam(\n    growth=dict(growth_term=None),\n    seasonality=dict(\n        yearly_seasonality=[False],\n        quarterly_seasonality=[False],\n        monthly_seasonality=[False],\n        weekly_seasonality=[False],\n        daily_seasonality=[False]\n    ),\n    custom=dict(\n        fit_algorithm_dict=dict(fit_algorithm=\"ridge\"),\n        extra_pred_cols=extra_pred_cols\n    ),\n    regressors=dict(regressor_cols=None),\n    autoregression=autoregression,\n    uncertainty=dict(uncertainty_dict=None),\n    events=dict(holiday_lookup_countries=None),\n)\n\n# Run the forecast model\nforecaster = Forecaster()\nresult = forecaster.run_forecast_config(\n    df=df,\n    config=ForecastConfig(\n        model_template=ModelTemplateEnum.SILVERKITE.name,\n        coverage=0.95,\n        forecast_horizon=forecast_horizon,\n        metadata_param=meta_data_params,\n        evaluation_period_param=evaluation_period_param,\n        model_components_param=model_components\n    )\n)\n\n# Get the useful fields from the forecast result\nmodel = result.model[-1]\nbacktest = result.backtest\nforecast = result.forecast\ngrid_search = result.grid_search\n\n# Check model coefficients / variables\n# Get model summary with p-values\nprint(model.summary())\n\n# Get cross-validation results\ncv_results = summarize_grid_search_results(\n    grid_search=grid_search,\n    decimals=2,\n    cv_report_metrics=None,\n    column_order=[\n        \"rank\", \"mean_test\", \"split_test\", \"mean_train\", \"split_train\",\n        \"mean_fit_time\", \"mean_score_time\", \"params\"])\n# Transposes to save space in the printed output\nprint(cv_results.transpose())\n\n# Check historical evaluation metrics (on the historical training/test set).\nbacktest_eval = defaultdict(list)\nfor metric, value in backtest.train_evaluation.items():\n    backtest_eval[metric].append(value)\n    backtest_eval[metric].append(backtest.test_evaluation[metric])\nmetrics = pd.DataFrame(backtest_eval, index=[\"train\", \"test\"]).T\nprint(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit/backtest plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = backtest.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forecast plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = forecast.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The components plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = forecast.plot_components()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit a model with time-varying seasonality (month effect).\nThis is achieved by adding ``\"ct1*C(month)\"`` to ``ModelComponentsParam``.\nNote that this feature may or may not be useful in your use case.\nWe have included this for demonstration purposes only.\nIn this example, while the fit has improved the backtest is inferior to the previous setting.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "extra_pred_cols = [\"ct_sqrt\", \"ct1\", \"C(month, levels=list(range(1, 13)))\",\n                   \"ct1*C(month, levels=list(range(1, 13)))\"]\nautoregression = {\n    \"autoreg_dict\": {\n        \"lag_dict\": {\"orders\": [1]},\n        \"agg_lag_dict\": None\n    }\n}\n\n# Specify the model parameters\nmodel_components = ModelComponentsParam(\n    growth=dict(growth_term=None),\n    seasonality=dict(\n        yearly_seasonality=[False],\n        quarterly_seasonality=[False],\n        monthly_seasonality=[False],\n        weekly_seasonality=[False],\n        daily_seasonality=[False]\n    ),\n    custom=dict(\n        fit_algorithm_dict=dict(fit_algorithm=\"ridge\"),\n        extra_pred_cols=extra_pred_cols\n    ),\n    regressors=dict(regressor_cols=None),\n    autoregression=autoregression,\n    uncertainty=dict(uncertainty_dict=None),\n    events=dict(holiday_lookup_countries=None),\n)\n\n# Run the forecast model\nforecaster = Forecaster()\nresult = forecaster.run_forecast_config(\n    df=df,\n    config=ForecastConfig(\n        model_template=ModelTemplateEnum.SILVERKITE.name,\n        coverage=0.95,\n        forecast_horizon=forecast_horizon,\n        metadata_param=meta_data_params,\n        evaluation_period_param=evaluation_period_param,\n        model_components_param=model_components\n    )\n)\n\n# Get the useful fields from the forecast result\nmodel = result.model[-1]\nbacktest = result.backtest\nforecast = result.forecast\ngrid_search = result.grid_search\n\n# Check model coefficients / variables\n# Get model summary with p-values\nprint(model.summary())\n\n# Get cross-validation results\ncv_results = summarize_grid_search_results(\n    grid_search=grid_search,\n    decimals=2,\n    cv_report_metrics=None,\n    column_order=[\n        \"rank\", \"mean_test\", \"split_test\", \"mean_train\", \"split_train\",\n        \"mean_fit_time\", \"mean_score_time\", \"params\"])\n# Transposes to save space in the printed output\nprint(cv_results.transpose())\n\n# Check historical evaluation metrics (on the historical training/test set).\nbacktest_eval = defaultdict(list)\nfor metric, value in backtest.train_evaluation.items():\n    backtest_eval[metric].append(value)\n    backtest_eval[metric].append(backtest.test_evaluation[metric])\nmetrics = pd.DataFrame(backtest_eval, index=[\"train\", \"test\"]).T\nprint(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit/backtest plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = backtest.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forecast plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = forecast.plot()\nplotly.io.show(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The components plot:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = forecast.plot_components()\nplotly.io.show(fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}