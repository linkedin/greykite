{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Grid Search\n\nForecast models have many hyperparameters that could significantly affect\nthe accuracy. These hyperparameters control different components\nin the model including trend, seasonality, events, etc.\nYou can learn more about how to configure the components or hyperparameters in\nthe model tuning tutorial (:doc:`/gallery/tutorials/0100_forecast_tutorial`). Here we\nwill see a step-by-step example of how to utilize the \"grid search\" functionality\nto choose the best set of hyperparameters.\n\nAll model templates support grid search.\nHere we continue the model tuning tutorial\nexample to use the ``SILVERKITE`` model on the Peyton Manning data set.\nThe mechanism of using grid search in ``PROPHET`` is similar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom greykite.common.data_loader import DataLoader\nfrom greykite.common.evaluation import EvaluationMetricEnum\nfrom greykite.framework.templates.autogen.forecast_config import ComputationParam\nfrom greykite.framework.templates.autogen.forecast_config import EvaluationMetricParam\nfrom greykite.framework.templates.autogen.forecast_config import EvaluationPeriodParam\nfrom greykite.framework.templates.autogen.forecast_config import ForecastConfig\nfrom greykite.framework.templates.autogen.forecast_config import ModelComponentsParam\nfrom greykite.framework.templates.forecaster import Forecaster\nfrom greykite.framework.templates.model_templates import ModelTemplateEnum\nfrom greykite.framework.utils.result_summary import summarize_grid_search_results\n\n# Loads dataset into pandas DataFrame\ndl = DataLoader()\ndf = dl.load_peyton_manning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grid search hyperparameters\n\nIn :doc:`/gallery/tutorials/0100_forecast_tutorial`\nwe learned how the components affect the prediction and how to choose the potential\ncandidate components. We also learned how to interpret the cross-validation results\nfor one set of hyperparameters. In this section, we will go over the ``grid_search``\nfunctionality that allows us to compare different sets of hyperparameters by running\ncross-validation on them automatically.\n\nIn the `~greykite.framework.templates.autogen.forecast_config.ModelComponentsParam` class,\neach attribute contains a dictionary mapping parameter names to parameter values. You may\nspecify either a specific parameter value to use, or a list of values to explore via grid search.\nGrid search is done over every possible combination of hyperparameters across the lists.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>You may only provide lists for these attributes' parameter values, not for the parameter values\n  of these attributes' parameter values if they are dictionaries.\n  For example, ``seasonality`` is an attribute in ``ModelComponentsParam``,\n  which has parameter names ``yearly_seasonality``, ``quarterly_seasonality``, etc.\n  We can provide lists for the parameter values of these names.\n  On the other hand, ``changepoints`` is an attribute, too,\n  which has parameter names ``changepoints_dict`` and ``seasonality_changepoints_dict``.\n  Both names take dictionaries as their parameter values.\n  We can provide lists of dictionaries as the values, however, within each dictionary,\n  we are not allowed to further wrap parameters in lists.</p></div>\n\nCross-validation will be performed over these sets of hyperparameters, and the best set of hyperparameters\nwill be selected based on the metric you pick, specified by ``cv_selection_metric`` in\n`~greykite.framework.templates.autogen.forecast_config.EvaluationMetricParam`.\n\nNow consider that we want to compare different yearly seasonalities (10 or 20), trend changepoints (None or \"auto\")\nand fit algorithms (linear or ridge), while keeping all other model components the same. We could specify:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seasonality = {\n    \"yearly_seasonality\": [10, 20],  # yearly seasonality could be 10 or 20\n    \"quarterly_seasonality\": False,\n    \"monthly_seasonality\": False,\n    \"weekly_seasonality\": False,\n    \"daily_seasonality\": False\n}\n\nchangepoints = {\n    # Changepoints could be None or auto.\n    \"changepoints_dict\": [\n        None,\n        {\"method\": \"auto\"}\n    ]\n}\n\n# Specifies custom parameters\ncustom = {\n    \"fit_algorithm_dict\": [\n        {\"fit_algorithm\": \"ridge\"},\n        {\"fit_algorithm\": \"linear\", \"fit_algorithm_params\": dict(missing=\"drop\")}\n    ]\n}\n\n# Specifies the model components\n# Could leave the other components as default,\n# or specify them in the normal way.\nmodel_components = ModelComponentsParam(\n    seasonality=seasonality,\n    changepoints=changepoints,\n    custom=custom\n)\n\n# Specifies the metrics\nevaluation_metric = EvaluationMetricParam(\n    # The metrics in ``cv_report_metrics`` will be calculated and reported.\n    cv_report_metrics=[EvaluationMetricEnum.MeanAbsolutePercentError.name,\n                       EvaluationMetricEnum.MeanSquaredError.name],\n    # The ``cv_selection_metric`` will be used to select the best set of hyperparameters.\n    # It will be added to ``cv_report_metrics`` if it's not there.\n    cv_selection_metric=EvaluationMetricEnum.MeanAbsolutePercentError.name\n)\n\n# Specifies the forecast configuration.\n# You could also specify ``forecast_horizon``, ``metadata_param``, etc.\nconfig = ForecastConfig(\n    model_template=ModelTemplateEnum.SILVERKITE.name,\n    model_components_param=model_components,\n    evaluation_metric_param=evaluation_metric\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the configuration above, all other model components parameters are the same but yearly seasonality,\nchangepoints and fit algorithm have 2 options each. The model will automatically run\ncross-validation over the 8 cases:\n\n  - yearly seasonality = 10, no changepoints, fit algorithm = \"linear\".\n  - yearly seasonality = 20, no changepoints, fit algorithm = \"linear\".\n  - yearly seasonality = 10, automatic changepoints, fit algorithm = \"linear\".\n  - yearly seasonality = 20, automatic changepoints, fit algorithm = \"linear\".\n  - yearly seasonality = 10, no changepoints, fit algorithm = \"ridge\".\n  - yearly seasonality = 20, no changepoints, fit algorithm = \"ridge\".\n  - yearly seasonality = 10, automatic changepoints, fit algorithm = \"ridge\".\n  - yearly seasonality = 20, automatic changepoints, fit algorithm = \"ridge\".\n\nThe CV test scores will be reported for all 8 cases using the metrics in ``cv_report_metrics``,\nand the final model will be trained on the best set of hyperparameters according to the\n``cv_selection_metric``.\n\n## Selective grid search\nConsider the case when you have 6 model components to tune, each with 3 different candidates.\nIn this case, there will be 3^6=729 different sets of hyperparameters to grid search from.\nThe results might be convincing because of the exhaustive grid search, however, the running\ntime is going to pile up.\n\nIt's very common that not all of the 729 sets of hyperparameters makes sense to us, so it\nwould be good not to run all of them. There are two ways to do selective grid search:\n\n  - Setting ``hyperparameter_budget``.\n  - Utilizing ``hyperparameter_override``.\n\n### Setting ``hyperparameter_budget``\nThe ``hyperparameter_budget`` parameter directly controls how many sets of hyperparameters\nwill be used in grid search. If this number is less than the number of all possible sets\nof hyperparameters, the algorithm will randomly pick ``hyperparameter_budget`` number of\nhyperparameter sets. Set ``hyperparameter_budget`` to ``-1`` to search all possible sets.\nYou may set the budget in the ``ComputationParam`` class. This is a simple way to search a\nlarge space of hyperparameters if you are not sure which are likely to succeed. After you\nidentify parameter values with better performance, you may run a more precise grid search\nto fine tune around these values.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you have a small number of timeseries to forecast, we recommend using the\n  model tuning tutorial (:doc:`/gallery/tutorials/0100_forecast_tutorial`)\n  to help identify good parameters candidates. This is likely more effective than\n  random grid search over a large grid.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Specifies the hyperparameter_budget.\n# Randomly picks 3 sets of hyperparameters.\ncomputation = ComputationParam(\n    hyperparameter_budget=3\n)\n# Specifies the forecast configuration.\n# You could also specify ``forecast_horizon``, ``metadata_param``, etc.\nconfig = ForecastConfig(\n    model_template=ModelTemplateEnum.SILVERKITE.name,\n    model_components_param=model_components,\n    evaluation_metric_param=evaluation_metric,\n    computation_param=computation\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utilizing ``hyperparameter_override``\nThe ``hyperparameter_override`` functionality allows us to customize the sets of hyperparameters\nto search within. The way is to specify the ``hyperparameter_override`` parameter in the\n``ModelComponentsParam`` class.\nFirst, model components are translated to the parameters in the corresponding sklearn Estimator\nfor the template (`~greykite.sklearn.estimator.simple_silverkite_estimator.SimpleSilverkiteEstimator`\nand `~greykite.sklearn.estimator.prophet_estimator.ProphetEstimator`). The name is usually the same as the\nkey, for example, \"estimator__yearly_seasonality\" and \"estimator__fit_algorithm_dict\" (the ``ModelComponentsParam``\nattribute is ignored). This creates a default hyperparameter_grid dictionary. Then for each dict in\n``hyperparameter_override``, the default grid's values are replaced by the override values, producing a\nlist of customized grids to search over. Grid search done across all the grids in the list.\nFor more details, see\n`hyperparameter override <../../../pages/model_components/1000_override.html#selective-grid-search>`_.\nNow assume we have the following parameter options, as above:\n\n  - yearly seasonality orders: 10 and 20.\n  - trend changepoints: None and \"auto\".\n  - fit algorithm: linear and ridge.\n\nWe do not want to run all 8 sets of hyperparameters. For example, we think that\nridge is not needed for the model without changepoints because the model is simple, while linear should\nnot be used when there are changepoints because the model is complex. So we want:\n\n  - for no changepoints we use linear regression only.\n  - for automatic changepoints we use ridge regression only.\n\nThen we can specify:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "seasonality = {\n    \"yearly_seasonality\": [10, 20],\n    \"quarterly_seasonality\": False,\n    \"monthly_seasonality\": False,\n    \"weekly_seasonality\": False,\n    \"daily_seasonality\": False\n}\n\nchangepoints = {\n    \"changepoints_dict\": None\n}\n\n# Specifies custom parameters\ncustom = {\n    \"fit_algorithm_dict\": {\"fit_algorithm\": \"linear\"}\n}\n\n# Hyperparameter override can be a list of dictionaries.\n# Each dictionary will be one set of hyperparameters.\noverride = [\n    {},\n    {\n        \"estimator__changepoints_dict\": {\"method\": \"auto\"},\n        \"estimator__fit_algorithm_dict\": {\"fit_algorithm\": \"ridge\"}\n    }\n]\n\n# Specifies the model components\n# Could leave the other components as default,\n# or specify them in the normal way.\nmodel_components = ModelComponentsParam(\n    seasonality=seasonality,\n    changepoints=changepoints,\n    custom=custom,\n    hyperparameter_override=override\n)\n\n# Specifies the evaluation period\nevaluation_period = EvaluationPeriodParam(\n    test_horizon=365,             # leaves 365 days as testing data\n    cv_horizon=365,               # each CV test size is 365 days (same as forecast horizon)\n    cv_max_splits=3,              # 3 folds CV\n    cv_min_train_periods=365 * 4  # uses at least 4 years for training because we have 8 years data\n)\n\nconfig = ForecastConfig(\n    forecast_horizon=365,\n    model_template=ModelTemplateEnum.SILVERKITE.name,\n    model_components_param=model_components,\n    evaluation_metric_param=evaluation_metric,\n    evaluation_period_param=evaluation_period\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The forecast configuration above specifies the yearly seasonality orders in\na list, therefore, both 10 and 20 will be searched. For the hyperparameter override\nlist, there are two elements. The first one is an empty dictionary, which corresponds\nto the original changepoint and fit algorithm in the configuration. The second dictionary\noverrides changepoint method with automatic changepoint detection and fit algorithm with ridge.\nIn total, the model will run 4 different configurations:\n\n  - yearly seasonality 10, no changepoint, fit algorithm linear.\n  - yearly seasonality 20, no changepoint, fit algorithm linear.\n  - yearly seasonality 10, automatic changepoints, fit algorithm ridge.\n  - yearly seasonality 20, automatic changepoints, fit algorithm ridge.\n\nIn this way, we could only search the sets of hyperparameters we need and save a lot of time.\nAlso note that the above configuration also configures the CV splits using\n`~greykite.framework.templates.autogen.forecast_config.EvaluationPeriodParam`.\nWe can see the configs and evaluations with ``summarize_grid_search_results``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Runs the forecast\nforecaster = Forecaster()\nresult = forecaster.run_forecast_config(\n    df=df,\n    config=config\n)\n\n# Summarizes the CV results\ncv_results = summarize_grid_search_results(\n    grid_search=result.grid_search,\n    decimals=1,\n    # The below saves space in the printed output. Remove to show all available metrics and columns.\n    cv_report_metrics=None,\n    column_order=[\"rank\", \"mean_test\", \"split_test\", \"mean_train\", \"split_train\", \"mean_fit_time\", \"mean_score_time\", \"params\"])\ncv_results[\"params\"] = cv_results[\"params\"].astype(str)\ncv_results.set_index(\"params\", drop=True, inplace=True)\ncv_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. tip::\n  The simple silverkite templates that use\n  `~greykite.sklearn.estimator.simple_silverkite_estimator.SimpleSilverkiteEstimator`\n  are the easiest templates to do grid search, because they support a list of model templates\n  and a list of ``ModelComponentsParam``. For more information, see\n  :doc:`/gallery/templates/0100_template_overview`.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}