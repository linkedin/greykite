{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Interpretability\n\nSilverkite generates easily interpretable forecasting models when using its default ML algorithms (e.g. Ridge).\nThis is because after transforming the raw features\nto basis functions (transformed features), the model uses an additive structure.\nSilverkite can break down each forecast into various summable components e.g. long-term growth,\nseasonality, holidays, events, short-term growth (auto-regression), regressors impact etc.\n\nThe approach to generate these breakdowns consists of two steps:\n\n#. Group the transformed variables into various meaningful groups.\n#. Calculate the sum of the features multiplied by their regression coefficients within each group.\n\nThese breakdowns then can be used to answer questions such as:\n\n- Question 1: How is the forecast value is generated?\n- Question 2: What is driving the change of the forecast as new data comes in?\n\nForecast components can also help us analyze model behavior and sensitivity.\nThis is because while it is not feasible to compare a large set of features across two model\nsettings, it can be quite practical and informative to compare a few well-defined components.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# required imports\nimport plotly\nimport warnings\nimport pandas as pd\nfrom greykite.framework.benchmark.data_loader_ts import DataLoaderTS\nfrom greykite.framework.templates.autogen.forecast_config import EvaluationPeriodParam\nfrom greykite.framework.templates.autogen.forecast_config import ForecastConfig\nfrom greykite.framework.templates.autogen.forecast_config import MetadataParam\nfrom greykite.framework.templates.autogen.forecast_config import ModelComponentsParam\nfrom greykite.framework.templates.forecaster import Forecaster\nfrom greykite.framework.templates.model_templates import ModelTemplateEnum\nfrom greykite.framework.utils.result_summary import summarize_grid_search_results\nfrom greykite.common.viz.timeseries_plotting import plot_multivariate\nwarnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to load and prepare data\nThis is the code to upload and prepare the daily bike-sharing data in Washington DC.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def prepare_bikesharing_data():\n    \"\"\"Loads bike-sharing data and adds proper regressors.\"\"\"\n    dl = DataLoaderTS()\n    agg_func = {\"count\": \"sum\", \"tmin\": \"mean\", \"tmax\": \"mean\", \"pn\": \"mean\"}\n    df = dl.load_bikesharing(agg_freq=\"daily\", agg_func=agg_func)\n\n    # There are some zero values which cause issue for MAPE\n    # This adds a small number to all data to avoid that issue\n    value_col = \"count\"\n    df[value_col] += 10\n    # We drop last value as data might be incorrect as original data is hourly\n    df.drop(df.tail(1).index, inplace=True)\n    # We only use data from 2018 for demonstration purposes (run time is shorter)\n    df = df.loc[df[\"ts\"] > \"2018-01-01\"]\n    df.reset_index(drop=True, inplace=True)\n\n    print(f\"\\n df.tail(): \\n {df.tail()}\")\n\n    # Creates useful regressors from existing raw regressors\n    df[\"bin_pn\"] = (df[\"pn\"] > 5).map(float)\n    df[\"bin_heavy_pn\"] = (df[\"pn\"] > 20).map(float)\n    df.columns = [\n        \"ts\",\n        value_col,\n        \"regressor_tmin\",\n        \"regressor_tmax\",\n        \"regressor_pn\",\n        \"regressor_bin_pn\",\n        \"regressor_bin_heavy_pn\"]\n\n    forecast_horizon = 7\n    train_df = df.copy()\n    test_df = df.tail(forecast_horizon).reset_index(drop=True)\n    # When using the pipeline (as done in the ``fit_forecast`` below),\n    # fitting and prediction are done in one step\n    # Therefore for demonstration purpose we remove the response values of last 7 days.\n    # This is needed because we are using regressors,\n    # and future regressor data must be augmented to ``df``.\n    # We mimic that by removal of the values of the response.\n    train_df.at[(len(train_df) - forecast_horizon):len(train_df), value_col] = None\n\n    print(f\"train_df shape: \\n {train_df.shape}\")\n    print(f\"test_df shape: \\n {test_df.shape}\")\n    print(f\"train_df.tail(14): \\n {train_df.tail(14)}\")\n    print(f\"test_df: \\n {test_df}\")\n\n    return {\n        \"train_df\": train_df,\n        \"test_df\": test_df}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Function to fit silverkite\nThis is the code for fitting a silverkite model to the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def fit_forecast(\n        df,\n        time_col,\n        value_col):\n    \"\"\"Fits a daily model for this use case.\n    The daily model is a generic silverkite model with regressors.\"\"\"\n\n    meta_data_params = MetadataParam(\n        time_col=time_col,\n        value_col=value_col,\n        freq=\"D\",\n    )\n\n    # Autoregression to be used in the function\n    autoregression = {\n        \"autoreg_dict\": {\n            \"lag_dict\": {\"orders\": [1, 2, 3]},\n            \"agg_lag_dict\": {\n                \"orders_list\": [[7, 7*2, 7*3]],\n                \"interval_list\": [(1, 7), (8, 7*2)]},\n            \"series_na_fill_func\": lambda s: s.bfill().ffill()},\n            \"fast_simulation\": True\n    }\n\n    # Changepoints configuration\n    # The config includes changepoints both in trend and seasonality\n    changepoints = {\n        \"changepoints_dict\": {\n            \"method\": \"auto\",\n            \"yearly_seasonality_order\": 15,\n            \"resample_freq\": \"2D\",\n            \"actual_changepoint_min_distance\": \"100D\",\n            \"potential_changepoint_distance\": \"50D\",\n            \"no_changepoint_distance_from_end\": \"50D\"},\n        \"seasonality_changepoints_dict\": {\n            \"method\": \"auto\",\n            \"yearly_seasonality_order\": 15,\n            \"resample_freq\": \"2D\",\n            \"actual_changepoint_min_distance\": \"100D\",\n            \"potential_changepoint_distance\": \"50D\",\n            \"no_changepoint_distance_from_end\": \"50D\"}\n        }\n\n    regressor_cols = [\n        \"regressor_tmin\",\n        \"regressor_bin_pn\",\n        \"regressor_bin_heavy_pn\",\n    ]\n\n    # Model parameters\n    model_components = ModelComponentsParam(\n        growth=dict(growth_term=\"linear\"),\n        seasonality=dict(\n            yearly_seasonality=[15],\n            quarterly_seasonality=[False],\n            monthly_seasonality=[False],\n            weekly_seasonality=[7],\n            daily_seasonality=[False]\n        ),\n        custom=dict(\n            fit_algorithm_dict=dict(fit_algorithm=\"ridge\"),\n            extra_pred_cols=None,\n            normalize_method=\"statistical\"\n        ),\n        regressors=dict(regressor_cols=regressor_cols),\n        autoregression=autoregression,\n        uncertainty=dict(uncertainty_dict=None),\n        events=dict(holiday_lookup_countries=[\"US\"]),\n        changepoints=changepoints\n     )\n\n    # Evaluation is done on same ``forecast_horizon`` as desired for output\n    evaluation_period_param = EvaluationPeriodParam(\n        test_horizon=None,\n        cv_horizon=forecast_horizon,\n        cv_min_train_periods=365*2,\n        cv_expanding_window=True,\n        cv_use_most_recent_splits=False,\n        cv_periods_between_splits=None,\n        cv_periods_between_train_test=0,\n        cv_max_splits=5,\n    )\n\n    # Runs the forecast model using \"SILVERKITE\" template\n    forecaster = Forecaster()\n    result = forecaster.run_forecast_config(\n        df=df,\n        config=ForecastConfig(\n            model_template=ModelTemplateEnum.SILVERKITE.name,\n            coverage=0.95,\n            forecast_horizon=forecast_horizon,\n            metadata_param=meta_data_params,\n            evaluation_period_param=evaluation_period_param,\n            model_components_param=model_components\n        )\n    )\n\n    # Gets cross-validation results\n    grid_search = result.grid_search\n    cv_results = summarize_grid_search_results(\n        grid_search=grid_search,\n        decimals=2,\n        cv_report_metrics=None)\n    cv_results = cv_results.transpose()\n    cv_results = pd.DataFrame(cv_results)\n    cv_results.columns = [\"err_value\"]\n    cv_results[\"err_name\"] = cv_results.index\n    cv_results = cv_results.reset_index(drop=True)\n    cv_results = cv_results[[\"err_name\", \"err_value\"]]\n\n    print(f\"\\n cv_results: \\n {cv_results}\")\n\n    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loads and prepares data\nThe data is loaded and some information about the input data is printed.\nWe use the number of daily rented bikes in Washington DC over time.\nThe data is augmented with weather data (precipitation, min/max daily temperature).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = prepare_bikesharing_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fits model to daily data\nIn this step we fit a silverkite model to the data which uses weather regressors,\nholidays, auto-regression etc.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = data[\"train_df\"]\ntime_col = \"ts\"\nvalue_col = \"count\"\nforecast_horizon = 7\n\nresult = fit_forecast(\n    df=df,\n    time_col=time_col,\n    value_col=value_col)\ntrained_estimator = result.model[-1]\n# Checks model coefficients and p-values\nprint(\"\\n Model Summary:\")\nprint(trained_estimator.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grouping of variables\nRegex expressions are used to group variables in the breakdown plot.\nEach group is given in one key of this dictionary.\nThe grouping is done using variable names and for each group multiple regex are given.\nFor each group, variables that satisfy EITHER regex are chosen.\nNote that this grouping assumes that regressor variables start with \"regressor_\".\nAlso note that the order of this grouping matters (Python treats the dictionary as ordered in 3.6+).\nThat means the variables chosen using regex in top groups will not be picked up again.\nIf some variables do not satisfy any of the groupings, they will be grouped into \"OTHER\".\nThe following breakdown dictionary should work for many use cases.\nHowever, the users can customize it as needed.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "grouping_regex_patterns_dict = {\n    \"regressors\": \"regressor_.*\",  # regressor effects\n    \"AR\": \".*lag\",  # autoregression component\n    \"events\": \".*events_.*\",  # events and holidays\n    \"seasonality\": \".*quarter.*|.*month.*|.*C\\(dow.*|.*C\\(dow_hr.*|sin.*|cos.*|.*doq.*|.*dom.*|.*str_dow.*|.*is_weekend.*|.*tow_weekly.*\",  # seasonality\n    \"trend\": \"ct1|ct2|ct_sqrt|ct3|ct_root3|.*changepoint.*\",  # long term trend (includes changepoints)\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creates forecast breakdown\nThis is generated for observed data plus the prediction data (available in ``df``).\nEach component is centered around zero and the sum of all components is equal to forecast.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "breakdown_result = trained_estimator.forecast_breakdown(\n    grouping_regex_patterns_dict=grouping_regex_patterns_dict,\n    center_components=True,\n    plt_title=\"forecast breakdowns\")\nforecast_breakdown_df = breakdown_result[\"breakdown_df_with_index_col\"]\nforecast_components_fig = breakdown_result[\"breakdown_fig\"]\nplotly.io.show(forecast_components_fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Standardization of the components\nNext we provide a more \"standardized\" view of the breakdown.\nThis is achieved by dividing all components by observed absolute value of the metric.\nBy doing so, intercept should be mapped to 1 and the y-axis changes can be viewed\nrelative to the average magnitude of the series.\nThe sum of all components at each time point will be equal to \"forecast / obs_abs_mean\".\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "column_grouping_result = breakdown_result[\"column_grouping_result\"]\ncomponent_cols = list(grouping_regex_patterns_dict.keys())\nforecast_breakdown_stdzd_df = forecast_breakdown_df.copy()\nobs_abs_mean = abs(df[value_col]).mean()\nfor col in component_cols + [\"Intercept\", \"OTHER\"]:\n    if col in forecast_breakdown_stdzd_df.columns:\n        forecast_breakdown_stdzd_df[col] /= obs_abs_mean\nforecast_breakdown_stdzd_fig = plot_multivariate(\n    df=forecast_breakdown_stdzd_df,\n    x_col=time_col,\n    title=\"forecast breakdowns divided by mean of abs value of response\",\n    ylabel=\"component\")\nforecast_breakdown_stdzd_fig.update_layout(yaxis_range=[-1.1, 1.1])\nplotly.io.show(forecast_breakdown_stdzd_fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Breaking down the predictions\nNext we perform a prediction and generate a breakdown plot for that prediction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "test_df = data[\"test_df\"].reset_index()\ntest_df[value_col] = None\nprint(f\"\\n test_df: \\n {test_df}\")\npred_df = trained_estimator.predict(test_df)\nforecast_x_mat = trained_estimator.forecast_x_mat\n# Generate the breakdown plot\nbreakdown_result = trained_estimator.forecast_breakdown(\n    grouping_regex_patterns_dict=grouping_regex_patterns_dict,\n    forecast_x_mat=forecast_x_mat,\n    time_values=pred_df[time_col])\n\nbreakdown_fig = breakdown_result[\"breakdown_fig\"]\nplotly.io.show(breakdown_fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Demonstrating a scenario-based breakdown\nWe artificially inject a \"bad weather\" day into test data on the second day of prediction.\nThis is done to observe if the breakdown plot captures a decrease in the collective regressors' effect.\nThe impact of the change in the regressor values can be clearly seen in the updated breakdown.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Altering the test data.\n# We alter the normal weather conditions on the second day to heavy precipitation and low temperature.\ntest_df[\"regressor_bin_pn\"] = [0, 1, 0, 0, 0, 0, 0]\ntest_df[\"regressor_bin_heavy_pn\"] = [0, 1, 0, 0, 0, 0, 0]\ntest_df[\"regressor_tmin\"] = [15, 0, 15, 15,  15, 15, 15]\nprint(f\"altered test_df: \\n {test_df}\")\n\n# Gets predictions and the design matrix used during predictions.\npred_df = trained_estimator.predict(test_df.reset_index())\nforecast_x_mat = trained_estimator.forecast_x_mat\n\n# Generates the breakdown plot.\nbreakdown_result = trained_estimator.forecast_breakdown(\n    grouping_regex_patterns_dict=grouping_regex_patterns_dict,\n    forecast_x_mat=forecast_x_mat,\n    time_values=pred_df[time_col])\nbreakdown_fig = breakdown_result[\"breakdown_fig\"]\nplotly.io.show(breakdown_fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}