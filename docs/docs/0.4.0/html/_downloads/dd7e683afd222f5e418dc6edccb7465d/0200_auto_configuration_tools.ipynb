{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Auto Configuration Tools\n\nThe Silverkite model has many hyperparameters to tune.\nBesides domain knowledge, we also have tools that can help\nfind good choices for certain hyperparameters.\nIn this tutorial, we will present\n\n  * seasonality inferrer\n  * holiday inferrer\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>If you use the model templates, you can specify the \"auto\" option for certain model components\n  (growth, seasonality and holiday),\n  and the auto configuration tool will be activated automatically.\n  See `auto seasonality <../../../pages/model_components/0300_seasonality.html#silverkite>`_,\n  `auto growth <../../../pages/model_components/0500_changepoints.html#auto-growth>`_ and\n  `auto holidays <../../../pages/model_components/0400_events.html#auto-holiday>`_ for the way to activate them.\n  This doc explains how the \"auto\" options work behind the code.\n  You can replay the \"auto\" options with the Seasonality Inferrer and Holiday Inferrer below.\n  Please remember that if you are doing train-test split,\n  running the inferrers on training data only is closer to the reality.</p></div>\n\n## Seasonality Inferrer\n\nThe Silverkite model uses Fourier series to model seasonalities.\nIt's sometimes difficult to decide what orders we should use\nfor each Fourier series.\nLarger orders tend to fit more closely to the curves, while having\nthe risk of overfitting.\nSmall orders tend to underfit the curve and may not learn the exact seasonality patterns.\n\n`~greykite.algo.common.seasonality_inferrer.SeasonalityInferrer`\nis a tool that can help you decide what order to use for a seasonality's Fourier series.\nNote that there are many ways to decide the orders,\nand you don't have to strictly stick to the results from Seasonality Inferrer.\n\n### How it works\n\nThe seasonality inferrer utilizes criteria including AIC and BIC to find the most\nappropriate Fourier series orders.\nFor a specific seasonality, e.g. yearly seasonality, the steps are as follows:\n\n* Trend removal: seasonality inferrer provides 4 options for trend removal.\n  They are listed in `~greykite.algo.common.seasonality_inferrer.TrendAdjustMethodEnum`.\n  Specifically:\n\n    * ``\"seasonal_average\"``: given an indicator of seasonal period, the method subtracts\n      the average within each seasonal period from the original time series.\n      For example, given the column ``year``, the average is calculated on each different year.\n    * ``\"overall_average\"``: subtracts the overall average from the original time series.\n    * ``\"spline_fit\"``: fits a polynomial up to a given degree and subtract from the original time series.\n    * ``\"none\"``: does not adjust the trend.\n\n  Typically \"seasonal_average\" is a good choice with appropriate columns.\n  For example, we can use ``year_quarter`` for quarterly seasonality, ``year_month`` for monthly seasonality,\n  ``year_woy_iso`` for weekly seasonality and ``year_woy_dow_iso`` for daily seasonality.\n* Optional aggregation: sometimes we want to get rid of shorter fluctuations before\n  fitting a longer seasonality period. We can do an optional aggregation beforehand.\n  For example, when we model yearly seasonality, we can do a ``\"7D\"`` aggregation to eliminate\n  weekly effects to make the result more stable.\n* With a pre-specified maximum order ``n``, we fit the de-trended (and aggregated) time series\n  with Fourier series from 1 to n, and calculate the AIC/BIC for those fits.\n  The most appropriate order is then decided by choosing the order with best AIC or BIC.\n  The method also allows to slightly sacrifice the criterion and reduce the order\n  for less risk of overfitting using the ``tolerance`` parameter.\n* Finally, an optional offset can be applied to any inferred orders to allow manual adjustments.\n  For example, if one would like to use less yearly seasonality order, they may specify\n  offset for yearly seasonality to be -2, and the final order will subtract 2 from the inferred result.\n  This is useful when users tend to use more or less orders to model seasonality,\n  and want a knob on top of the inferring results.\n\n### Example\n\nNow we look at an example with the Peyton-Manning Wiki page view data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport plotly\nfrom greykite.common.data_loader import DataLoader\nfrom greykite.algo.common.seasonality_inferrer import SeasonalityInferConfig\nfrom greykite.algo.common.seasonality_inferrer import SeasonalityInferrer\nfrom greykite.algo.common.seasonality_inferrer import TrendAdjustMethodEnum\nfrom greykite.common import constants as cst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The ``SeasonalityInferrer`` class uses\n`~greykite.algo.common.seasonality_inferrer.SeasonalityInferConfig`\nto specify configuration for a single seasonality component,\nand it takes a list of such configurations to infer multiple seasonality\ncomponents together.\nNow we specify seasonality inferring configs for yearly to weekly seasonalities.\nIn each of these configs, specify the parameters that are distinct for each component.\nIf there are parameters that are the same across all configs,\nyou can specify them in the function directly.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "yearly_config = SeasonalityInferConfig(\n    seas_name=\"yearly\",                     # name for seasonality\n    col_name=\"toy\",                         # column to generate Fourier series, fixed for yearly\n    period=1.0,                             # seasonal period, fixed for yearly\n    max_order=30,                           # max number of orders to model\n    adjust_trend_param=dict(\n        trend_average_col=\"year\"\n    ),                                      # column to adjust trend for method \"seasonal_average\"\n    aggregation_period=\"W\",                 # aggregation period,\n    offset=0                                # add this to the inferred result, default 0\n)\nquarterly_config = SeasonalityInferConfig(\n    seas_name=\"quarterly\",                  # name for seasonality\n    col_name=\"toq\",                         # column to generate Fourier series, fixed for quarterly\n    period=1.0,                             # seasonal period, fixed for quarterly\n    max_order=20,                           # max number of orders to model\n    adjust_trend_param=dict(\n        trend_average_col=\"year_quarter\"\n    ),                                      # column to adjust trend for method \"seasonal_average\"\n    aggregation_period=\"2D\",                # aggregation period\n)\nmonthly_config = SeasonalityInferConfig(\n    seas_name=\"monthly\",                    # name for seasonality\n    col_name=\"tom\",                         # column to generate Fourier series, fixed for monthly\n    period=1.0,                             # seasonal period, fixed for monthly\n    max_order=20,                           # max number of orders to model\n    adjust_trend_param=dict(\n        trend_average_col=\"year_month\"\n    ),                                      # column to adjust trend for method \"seasonal_average\"\n    aggregation_period=\"D\"                  # aggregation period\n)\nweekly_config = SeasonalityInferConfig(\n    seas_name=\"weekly\",                     # name for seasonality\n    col_name=\"tow\",                         # column to generate Fourier series, fixed for weekly\n    period=7.0,                             # seasonal period, fixed for weekly\n    max_order=10,                           # max number of orders to model\n    adjust_trend_param=dict(\n        trend_average_col=\"year_woy_iso\"\n    ),                                      # column to adjust trend for method \"seasonal_average\"\n    aggregation_period=\"D\",\n    tolerance=0.005,                        # allows 0.5% higher criterion for lower orders\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we put everything together to infer seasonality effects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = DataLoader().load_peyton_manning()\ndf[cst.TIME_COL] = pd.to_datetime((df[cst.TIME_COL]))\n\nmodel = SeasonalityInferrer()\nresult = model.infer_fourier_series_order(\n    df=df,\n    time_col=cst.TIME_COL,\n    value_col=cst.VALUE_COL,\n    configs=[\n        yearly_config,\n        quarterly_config,\n        monthly_config,\n        weekly_config\n    ],\n    adjust_trend_method=TrendAdjustMethodEnum.seasonal_average.name,\n    fit_algorithm=\"linear\",\n    plotting=True,\n    criterion=\"bic\",\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The method runs quickly and we can simply extract the inferred results\nfrom the output.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "result[\"best_orders\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the results to see how different orders vary the criterion.\nSimilar to other trade-off plots, the plot first goes down and then goes up,\nreaching the best at some appropriate value in the middle.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The [0] extracts the first seasonality component from the results.\nplotly.io.show(result[\"result\"][0][\"fig\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Holiday Inferrer\n\nThe Silverkite model supports modeling holidays and their neighboring days\nas indicators. Significant days are modeled separately,\nwhile similar days can be grouped together as one indicator,\nassuming their effects are the same.\n\nIt's sometimes difficult to decide which holidays to include,\nto model separately or to model together.\n`~greykite.algo.common.holiday_inferrer.HolidayInferrer`\nis a tool that can help you decide which holidays to model\nand how to model them.\nIt can also automatically generate the holiday configuration parameters.\nNote that there are many ways to decide the holiday configurations,\nand you don't have to strictly stick to the results from Holiday Inferrer.\n\n### How it works\n\nThe holiday inferrer estimates individual holiday or their\nneighboring days' effects by comparing the observations\non these days with some baseline prior to or after the holiday period.\nThen it ranks the effects by their magnitude.\nDepending on some thresholds, it decides whether to model\na day independently, together with others or do not model it.\n\nIn detail, the first step is to unify the data frequency.\nFor data whose frequency is greater than daily,\nholiday effect is automatically turned off.\nFor data whose frequency is less than daily,\nit is aggregated into daily data,\nsince holidays are daily events.\nFrom now on, we have daily data for the next step.\n\nGiven a list of countries, the tool automatically pulls candidate\nholidays from the database. With a ``pre_search_days`` and a ``post_search_days``\nparameters, those holidays' neighboring days are included in the candidate pool\nas well.\n\nFor every candidate holiday or neighboring day,\nthe baseline is the average of a configurable offsets.\nFor example, for data that exhibits strong weekly seasonality,\nthe offsets can be ``(-7, 7)``, where the baseline will be\nthe average of the last same day of week's observation and the\nnext same day of week's observation.\nFor example, if the holiday is New Year on 1/1 while 12/25 (7 days ago) is Christmas,\nit will look at the value on 12/18 instead of 12/25 as baseline.\n\nThe day's effect is the average of the signed difference between\nthe true observation and the baseline across all occurrences in the time series.\nThe effects are ranked from the highest to the lowest by their absolute effects.\n\nTo decide how each holiday is modeled, we rely on two parameters:\n``independent_holiday_thres`` and ``together_holiday_thres``.\nThese parameters are between 0 and 1.\nStarting from the largest effect,\nwe calculate the cumulative sum of effect of all candidates.\nOnce the cumulative effect reaches ``independend_holiday_thres`` of the total effects,\nthese days will be modeled independently (i.e, each day has an individual coefficient).\nWe keep accumulating effects until the sum reaches ``together_holiday_thres``,\nthe days in the between are grouped into \"positive_group\" and \"negative_group\",\nwith each group modeled together.\n\n### Example\n\nNow we look at an example with the Peyton-Manning Wiki page view data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\nimport plotly\nfrom greykite.algo.common.holiday_inferrer import HolidayInferrer\nfrom greykite.common.data_loader import DataLoader\nfrom greykite.common import constants as cst\n\ndf = DataLoader().load_peyton_manning()\ndf[cst.TIME_COL] = pd.to_datetime(df[cst.TIME_COL])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's say we want to infer the holidays in the United States,\nwith consideration on +/- 2 days of each holiday as potential candidates too.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hi = HolidayInferrer()\nresult = hi.infer_holidays(\n    df=df,\n    countries=[\"US\"],                   # Search holidays in United States\n    plot=True,                          # Output a plot\n    pre_search_days=2,                  # Considers 2 days before each holiday\n    post_search_days=2,                 # Considers 2 days after each holiday\n    independent_holiday_thres=0.9,      # The first 90% of effects are modeled separately\n    together_holiday_thres=0.99,        # The 90% to 99% of effects are modeled together\n    baseline_offsets=[-7, 7]            # The baseline is the average of -7/+7 observations\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the inferred holiday results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plotly.io.show(result[\"fig\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The class also has a method to generate the holiday configuration\nbased on the inferred results, that is consumable directly by the Silverkite model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hi.generate_daily_event_dict()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}