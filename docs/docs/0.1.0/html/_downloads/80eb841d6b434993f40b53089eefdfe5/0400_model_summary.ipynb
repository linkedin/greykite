{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nModel Summary\n=============\nFor every forecast model trained with the ``SILVERKITE`` algorithm,\nyou can print the model summary with only a few lines of code.\nThe model summary gives you insight into model performance,\nparameter significance and etc.\n\nIn this example, we will discuss how to utilize the\n`~greykite.algo.common.model_summary.ModelSummary`\nmodule to output model summary.\n\nFirst we'll load a dataset representing ``log(daily page views)``\non the Wikipedia page for Peyton Manning.\nIt contains values from 2007-12-10 to 2016-01-20. More dataset info\n`here <https://facebook.github.io/prophet/docs/quick_start.html>`_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nfrom greykite.common.data_loader import DataLoader\nfrom greykite.framework.templates.autogen.forecast_config import ForecastConfig\nfrom greykite.framework.templates.autogen.forecast_config import MetadataParam\nfrom greykite.framework.templates.autogen.forecast_config import ModelComponentsParam\nfrom greykite.framework.templates.model_templates import ModelTemplateEnum\nfrom greykite.framework.templates.forecaster import Forecaster\n\n# Loads dataset into pandas DataFrame\ndl = DataLoader()\ndf = dl.load_peyton_manning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create a forecast model with ``SILVERKITE`` template.\nFor a simple example of creating a forecast model, see\n`Simple Forecast <./0100_simple_forecast.html>`_.\nFor a detailed tuning tutorial, see\n`Forecast Model Tuning <../tutorials/0100_forecast_tutorial.html>`_.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Specifies dataset information\nmetadata = MetadataParam(\n    time_col=\"ts\",  # name of the time column\n    value_col=\"y\",  # name of the value column\n    freq=\"D\"  # \"H\" for hourly, \"D\" for daily, \"W\" for weekly, etc.\n)\n\n# Specifies model parameters\nmodel_components = ModelComponentsParam(\n    changepoints={\n        \"changepoints_dict\": {\n            \"method\": \"auto\",\n            \"potential_changepoint_n\": 25,\n            \"regularization_strength\": 0.5,\n            \"resample_freq\": \"7D\",\n            \"no_changepoint_distance_from_end\": \"365D\"}\n    },\n    uncertainty={\n        \"uncertainty_dict\": \"auto\",\n    },\n    custom={\n        \"fit_algorithm_dict\": {\n            \"fit_algorithm\": \"linear\",\n        },\n    }\n)\n\n# Runs the forecast\nforecaster = Forecaster()\nresult = forecaster.run_forecast_config(\n    df=df,\n    config=ForecastConfig(\n        model_template=ModelTemplateEnum.SILVERKITE.name,\n        forecast_horizon=365,  # forecasts 365 steps ahead\n        coverage=0.95,  # 95% prediction intervals\n        metadata_param=metadata,\n        model_components_param=model_components\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating model summary\n^^^^^^^^^^^^^^^^^^^^^^\nNow that we have the output from :py:meth:`~greykite.framework.templates.forecaster.Forecaster.run_forecast_config`,\nwe are able to access the model summary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Initializes the model summary class.\n# ``max_colwidth`` is the maximum length of predictor names that can be displayed.\nsummary = result.model[-1].summary(max_colwidth=30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above command creates a model summary class and derives extra information\nthat summarizes the model. Generally the summarized information includes\nthe following sections:\n\n  #. **Model parameter section:** includes basic model parameter information such\n     as number of observations, number of features, model name and etc.\n  #. **Model residual section:** includes the five number summary of training residuals.\n  #. **Model coefficients section (for regression model):** the estimated coefficients\n     and their p-values/confidence intervals. For linear regression, these are the\n     conventional results; for ridge regression, these are calculated from bootstrap [1]_;\n     for lasso regression, these are calculated by multi-sample-splitting [2]_.\n  #. **Model coefficients section (for tree model):** the feature significance.\n  #. **Model significance section (for regression model only):** the overall significance\n     of the regression model, including the coefficient of determination, the\n     F-ratio and its p-value, and model AIC/BIC. The results are based on classical\n     statistical inference and may not be reliable for regularized methods (ridge, lasso, etc.).\n  #. **Warning section:** any warnings for the model summary such as high multicollinearity\n     are displayed in this section.\n\nTo see the summary, you can either type ``summary`` or ``print(summary)``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Prints the summary\nprint(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model summary provides useful insights:\n\n  #. We can check the ``sig. code`` column to see which features are not significant.\n     For example, the \"Independence Day\" events are not significant,\n     therefore we could consider removing them from the model.\n  #. We can check the effect of each feature by examing the confidence interval.\n     For example, the Christmas day has a negative effect of -0.57, with a confidence interval\n     of -0.93 to -0.22. The changepoint at 2010-02-15 changes the slope by -2.52, with a\n     confidence interval of -3.60 to -1.44.\n\nFor linear regression, the results are the\nsame as the regular regression summary in R (the ``lm`` function).\nThe usual considerations apply when interpreting the results:\n\n  #. High feature correlation can increase the coefficient variance.\n     This is common in forecasting problems, so we recommend regularized models.\n  #. There is no standard way to calculate confidence intervals and p-values for regularized\n     linear models (ridge, lasso, elastic_net). We follow the approach in [1]_ for ridge\n     inference and [2]_ for lasso inference.\n     The ideas are to use bootstrap and sample-splitting, respectively.\n\n          - For ridge regression, the confidence intervals and p-values are based on biased estimators.\n            This is a remedy for multicollinearity to produce better forecast, but could lower the true\n            effect of the features.\n          - For lasso regression, the confidence intervals and p-values are based on a multi-sample-split\n            procedure. While this approach of generating CIs is optimized for accuracy, they are calculated\n            independently of the coefficient estimates and are not guaranteed to overlap with the estimates.\n            It's worth noting that the probability of a coefficient being nonzero is also reported in the column ``Prob_nonzero``.\n            This probability can be used to interpret the significance of the corresponding feature.\n\nMoreover, if you would like to explore the numbers behind the printed summary,\nthey are stored in the ``info_dict`` attribute, which is a python dictionary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Prints the keys of the ``info_dict`` dictionary.\nprint(summary.info_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# The above coefficient summary can be accessed as a pandas Dataframe.\nprint(summary.info_dict[\"coef_summary_df\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Selected features in a category\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nYou may have noticed that there are too many features in the forecast model.\nIt's not easy to read all of them in the coefficient summary table.\nThe model summary class is able to filter the categories of these features.\nThis is done by the\n`~greykite.algo.common.model_summary.ModelSummary.get_coef_summary`\nfunction.\n\nA few filters are available, including:\n\n  - ``is_intercept``: intercept term.\n  - ``is_time_feature``: features defined in `~greykite.common.features.timeseries_features.build_time_features_df`.\n  - ``is_event``: holidays and events.\n  - ``is_trend``: trend features.\n  - ``is_seasonality``: seasonality features.\n  - ``is_lag``: autoregressive features.\n  - ``is_regressor``: extra regressors provided by user.\n  - ``is_interaction``: interaction terms.\n\nAll filters set to ``True`` will be joined with the logical operator ``or``,\nwhile all filters set to ``False`` will be joined with the logical operator ``and``.\nSimply speaking, set what you want to see to ``True`` and what you don't want to see\nto ``False``.\n\nBy default, ``is_interaction`` is set to ``True``, this means as long as one feature in\nan interaction term belongs to a category set to ``True``, the interaction term is included\nin the output. However, if one feature in an interaction term belongs to a category set to\n``False``, the interaction is excluded from the output.\nTo hide interaction terms, set ``is_interaction`` to ``False``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Displays intercept, trend features but not seasonality features.\nsummary.get_coef_summary(\n    is_intercept=True,\n    is_trend=True,\n    is_seasonality=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There might be too many featuers for the trend (including interaction terms).\nLet's hide the interaction terms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Displays intercept, trend features but not seasonality features.\n# Hides interaction terms.\nsummary.get_coef_summary(\n    is_intercept=True,\n    is_trend=True,\n    is_seasonality=False,\n    is_interaction=False\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can see the pure trend features, including the continuous growth term and trend changepoints.\nEach changepoint's name starts with \"cp\" followed by the time point it happens.\nThe estimated coefficients are the changes in slope at the corresponding changepoints.\nWe can also see the significance of the changepoints by examining their p-values.\n\nWe can also retrieve the filtered dataframe by setting ``return_df`` to ``True``.\nThis way you could further explore the coefficients.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "output = summary.get_coef_summary(\n    is_intercept=True,\n    is_trend=True,\n    is_seasonality=False,\n    is_interaction=False,\n    return_df=True  # returns the filtered df\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. [1] Reference: \"An Introduction to Bootstrap\", Efron 1993.\n.. [2] Reference: \"High-Dimensional Inference: Confidence Intervals, p-Values and R-Software hdi\", Dezeure, Buhlmann, Meier and Meinshausen.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}